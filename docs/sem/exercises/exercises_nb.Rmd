---
title: "SEM Exercises"
author: |
  | Michael Clark
  | Statistician Lead
  | Consulting for Statistics, Computing and Analytics Research

date: '`r Sys.Date()`'
output:
  html_notebook:
    # css: ../latent.css # using latent will mess up line breaks in code (only for notebook)
    theme: sandstone
    font-family: Roboto
    highlight: pygments
    toc: TRUE
    toc_float: TRUE
    code_folding: hide
---
 
```{r setupExercises, include=FALSE}
knitr::opts_chunk$set(cache = F, message = F, warning = F, R.options=list(width=120), comment=NA)
library(magrittr); library(dplyr); library(lavaan)
```



# Exercises
## Path Analysis
### Part 1

This exercise investigates satisfaction in high school seniors using the 1993 Monitoring the Future dataset (`'data/monitorfuture.csv'`). Perform a path analysis on the four measured variables: self-esteem (esteem), overall life satisfaction (overall), locus of control (locus), and loneliness (lonely). Estimate the following model using lavaan (note that the dashed line is an 'unanalyzed' correlation and doesn't need to be explicit in the model).

<br>

```{r paExercise1Old, eval=FALSE, echo=FALSE, results='hide'}
mcclelland = haven::read_dta('../data/path_analysis_data.dta')
library(lavaan)
modMath = 
"
  math21 ~ math7 + read7
  math7 ~ attention4
  read7 ~ attention4
"
math  = sem(modMath, data=mcclelland)
summary(math, rsquare=TRUE)
semPlot::semPaths(math, style='lisrel', rotation = 2, layout = 'tree2', intercepts = F)
```

```{r pa1, echo=FALSE}
mtf = read.csv('../data/monitorfuture.csv')
satistifaction_ModelCode = '
  overall ~ esteem + lonely
  esteem ~ locus + lonely
'
satistifaction_ModelResults = sem(satistifaction_ModelCode, data=mtf)
semPlot::semPaths(satistifaction_ModelResults, residuals=F, style='lisrel', sizeMan=8,
                  edgeLabels='', residScale=10, nCharNodes=6, exoVar=F, rotation=2)
```

First get the data in, then set up your model code.  The following provides a hint.

```{r pa1Hint1, eval=FALSE, code.fold='hide'}
mtf = read.csv('filelocation/name.csv')

satistifaction_ModelCode = 'Y ~ X + z'
```

After that, run the model using the <span class="func">sem</span> function in <span class="package">lavaan</span>.  The following provides a hint.

```{r pa1Hint2,  eval=FALSE}
satistifaction_ModelResults = sem(modelcodename, data=modeldataname)

summary(satistifaction_ModelResults, rsquare=T)
```


Your results should be consistent with the following graph.

```{r paResults, echo=FALSE, results='hide', eval=-6}
satistifaction_ModelResults = sem(satistifaction_ModelCode, data=mtf)
summary(satistifaction_ModelResults, rsquare=T)

# to visualize
library(semPlot)
semPaths(satistifaction_ModelResults, whatLabels='est', style='lisrel', rotation=2)
```
```{r echo=FALSE}
# or color based on direction, fade with size, using standardized estimates
semPaths(satistifaction_ModelResults, what='std', style='lisrel', 
         layout='tree2', rotation=2, covAtResiduals=F, 
         sizeMan=10, edge.label.cex=1.5, color='#ff5503', borders=F, 
         label.color='#ffffff')
```


<br>

Questions:

1. What are the positive effects in this model?

2. What are the negative effects in this model?

3. What is your initial impression about model performance?

4. What specifically are the R^2^ values for the endogenous variables?


### Part 2

Rerun with the following model (click to show).

<br>

```{r mediationExercise, eval=FALSE}
satistifaction_ModelCode_Mediation = '
  overall ~ c*esteem + lonely
  esteem ~ a*locus + b*lonely

  # Indirect effects
  locusOverall := a*c
  lonelyOverall := b*c
'
```

<br>

Regarding this mediation model... 

  - A. Is the indirect effect for loneliness on life satisfaction statistically significant? 
  - B. How about locus of control?
  - C. Do you think loneliness causes self-esteem (more lonely, less self-esteem), or vice versa, or perhaps they are simply correlated?

<br><br><br>




## Factor Analysis

### Part 1

Data: National Longitudinal Survey of Youth (1997, NLSY97), which investigates the transition from youth to adulthood. For this example, a series of questions asked to the participants in 2006 pertaining to the government’s role in promoting well-being will be investigated. Questions regarded the government's responsibility for following issues: provide jobs for everyone, keep prices under control, provide health care, provide for elderly, help industry, provide for unemployed, reduce income differences, provide college financial aid, provide decent housing, protect environment.  They have four values 1:4, which range from 'definitely should be' to 'definitely should not be'.


1. Run a factor analysis using the `'data/nlsy97_governmentNumeric.csv'` dataset.  Your first model will have all items (sans ID) loading on a single factor, with a name of your choosing.  With <span class="pack">lavaan</span>, use the <span class="func">cfa</span> function.  Recall that you give it the model code (as a <span class="objclass">string</span>) and a `data = ` argument like `cfa(mod, data=mydata)`.

Try it on your own or click to see the general format.

```{r fa1Starter, eval=FALSE}
govtInvolvement = read.csv('data/nlsy97_governmentNumeric.csv')
govtInvolvement_ModelCode = 'Your Model Here'
govtInvolvement_Results = cfa(govtInvolvement_ModelCode)
summary(govtInvolvement_Results, standardized=T, fit=T)
```

<br><br>

2. Note the standardized loadings, are the items 'hanging together' well?  Do you see any that might be we somewhat weak?



### Part 2

3. Now specify a two factor structure *of your choosing*. As an example, some of these are maybe more economic in nature, while others might fit in some other category.  Whatever makes sense to you, or just randomly split it.

4. Does this seem any more interpretable?  Were the latent variables notably correlated? Which model would you say is better based on internal performance, in terms of comparison (e.g. lower AIC = preferred model), and in terms of interpretability?


Click to show example (after you've tried yourself).
<br>

```{r fa2, eval=FALSE, bootstrap.show.code=F}
library(lavaan)
govtInvolvement = read.csv('../data/nlsy97_governmentNumeric.csv')

govtInvolvement_ModelCode1 = "
  moregovt =~ ProvideJobs + Prices + HealthCare + Elderly + Industry + Unemployed + IncInequal + College + Housing + Environment
"
model1 = cfa(govtInvolvement_ModelCode1, data=govtInvolvement) 
summary(model1, fit=T, standardized=T)

govtInvolvement_ModelCode2 = '
  econ =~ ProvideJobs + Industry + Unemployed + IncInequal + Housing + Prices
  services =~ HealthCare + Elderly + College + Environment
'
model2 = cfa(govtInvolvement_ModelCode2, data=govtInvolvement) 
summary(model2, fit=T, standardized=T)

# Compare the two († means the better result)
semTools::compareFit(model1, model2, nested=F)
```


<br><br><br>

## SEM

You get the choice of doing exercise 1 or 2.

### Exercise 1

The data for this exercise comes from a paper published by Marsh and Hocevar in 1985. The data regards information on 385 fourth and fifth grade students who filled out a ‘Self-Description Questionnaire.’ The questionnaire has 16 items, four of which measure physical ability, four measure physical appearance, four measure relations with peers and the final four measure relations with parents. The data is saved in the file ‘Marsh85.dta’ as summary data with means, standard deviations and correlations.  However you will just use 'Marsh85_SEMExercise.csv', which is the covariance matrix.

We are interested in determining how a student’s physical appearance and physical ability might predict relationships with their peers. The diagram for the model of interest is shown below.

<br><br><br>

```{r sem1, echo=FALSE, results='hide'}
marsh = haven::read_dta('../data/Marsh85.dta')  # grade 1 and 2 are 4 and fifth, first two rows of each are the means and sd

marshCov = marsh %>%
  filter(grade==1) %>%
  select(contains('phyab'), contains('appear'), contains('peer')) %>%
  slice(-(1:2)) %>%
  slice(1:12) %>%
  data.matrix
rownames(marshCov) = colnames(marshCov)
meanssds =  marsh %>%  slice(1:2) %>% select(contains('phyab'), contains('appear'), contains('peer'))

marshCov = lavaan::cor2cov(R=marshCov, sds=unlist(meanssds[2,]))

# write.csv(marshCov, file='../data/Marsh85_SEMExercise.csv', row.names=T)
marshCov = read.csv('../data/Marsh85_SEMExercise.csv', row.names = 1)  
marshCov = as.matrix(marshCov)


peerRel_ModelCode = "
  # Measurement models
  Appearance =~ appear1 + appear2 + appear3 + appear4
  Ability =~ phyab1 + phyab2 + phyab3 + phyab4
  Relations =~ peerrel1 + peerrel2 + peerrel3 + peerrel4

  # Structural Models
  Relations ~ Ability + Appearance
"
library(lavaan)
peerRel_Results = sem(peerRel_ModelCode, sample.cov=marshCov, sample.nobs=385)
summary(peerRel_Results)
```

```{r sem1fig, echo=FALSE, fig.align='center', dev='svg'}
# semPlot::semPaths(peerRel_Results, residuals=T, style='lisrel', edgeLabels='', 
#                   residScale=10, nCharNodes=6, exoVar=T, edge.label.cex=1)
semPlot::semPaths(peerRel_Results, layout='tree2', style='lisrel', covAtResiduals=F, residuals = T,
                  groups=c('latent', 'man'),  color=list(latent='#ff5503', man=scales::alpha('#ff5503',.5)),
                  sizeMan=5, sizeLat=10, edge.label.cex=1.5, borders=F, #edge.color='#1e90ff',
                  nCharNodes=6, exoVar=T,
                  label.color='#ffffff') 
```

<br>

The following will get you started. All you need to do is fill in the model code. Rather than raw data, we will be using the sample covariance matrix with sample size equal to 385. Note how you can detect the structure visually.  Physical ability hangs together well and is positively correlated with the other factors, which are more strongly correlated with each other.  This is extremely important in factor analysis and SEM, as they deal with the correlation matrix, you should often be able to see the structure before modeling even begins.



```{r corplot, echo=FALSE, eval=T, message=F, warning=F}
# corrplot::corrplot(cov2cor(marshCov), order='hclust', addrect=3, rect.col='#ff5503', tl.col='gray50')
suppressMessages(lazerhawk::corrheat(cov2cor(marshCov)))  # knitr won't ignore message otherwise
```

<br>

```{r sem1Starter, eval=FALSE}
marsh85 = read.csv('../data/Marsh85_SEMExercise.csv', row.names = 1)
marsh85 = as.matrix(marsh85)
peerRel_ModelCode = ''
peerRel_Results = sem(peerRel_ModelCode, sample.cov=marsh85, sample.nobs=385)
summary(peerRel_Results, standardized=T, fit=T, rsquare=T)
```

<br><br>

> Write a brief summary in terms of an assessment of the measurement components of the model, overall impression of model fit, and specifics of the structural relations (i.e. the paths among the latent variables) and model performance in terms of R^2^.




### Exercise 2

In this second example, we will use the classic Political Democracy dataset used by Bollen in his seminal 1989 book on structural equation modeling. This data set includes four measures of democracy at two points in time, 1960 and 1965, and three measures of industrialization in 1960, for 75 developing countries.

- FoPress60: freedom of the press, 1960
- FoPopp60: freedom of political opposition, 1960
- FairElect60: fairness of elections, 1960
- EffectiveLeg60: effectiveness of elected legislature, 1960
- FoPress65: freedom of the press, 1965
- FoPopp65: freedom of political opposition, 1965
- FairElect65: fairness of elections, 1965
- EffectiveLeg65: effectiveness of elected legislature, 1965
- GNP60: GNP per capita, 1960
- EnConsump60: energy consumption per capita, 1960
- PercLaborForce60: percentage of labor force in industry, 1960

The model we wish to estimate is in according to the following diagram.

<br><br>

```{r sem2, echo=F}
poldem = read.csv('../data/PoliticalDemocracy.csv')
poldem_ModelCode = '
  # measurement model
    ind60 =~ GNP60 + EnConsump60 + PercLaborForce60
    dem60 =~ FoPress60 + FoPopp60 + FairElect60 + EffectiveLeg60
    dem65 =~ FoPress65 + FoPopp65 + FairElect65 + EffectiveLeg65
  # regressions
    dem60 ~ ind60
    dem65 ~ ind60 + dem60
'
poldem_Results = sem(poldem_ModelCode, data=poldem)
semPlot::semPaths(poldem_Results, layout='tree2', style='lisrel', covAtResiduals=F, residuals = T,
                  groups=c('latent', 'man'),  color=list(latent='#ff5503', man=scales::alpha('#ff5503',.5)),
                  sizeMan=5, sizeLat=10, edge.label.cex=1.5, borders=F, #edge.color='#1e90ff',
                  nCharNodes=6, exoVar=T,
                  label.color='#ffffff') 
```

<br><br><br>

```{r corplotsem2, echo=FALSE, eval=F}
# corrplot::corrplot(cor(poldem), order='hclust', addrect=3, rect.col='#ff5503', tl.col='gray50')
lazerhawk::corrheat(cor(poldem))
```

<br><br>

Here is some starter code. All you need to do is fill in the model code.

<br><br>

```{r sem2Starter, eval=FALSE}
poldem = read.csv('data/PoliticalDemocracy.csv')
poldem_ModelCode = ''
poldem_Results = sem(poldem_ModelCode, data=poldem)
summary(poldem_Results, standardized=T, fit=T, rsquare=T)
```


<br><br>

> Write a brief summary in terms of an assessment of the measurement components of the model, overall impression of model fit, and specifics of the structural relations (i.e. the paths among the latent variables) and model performance in terms of R^2^.


