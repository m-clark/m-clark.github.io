@article{shwartz2021tabular,
  title={Tabular Data: Deep Learning is Not All You Need},
  author={Shwartz-Ziv, Ravid and Armon, Amitai},
  journal={arXiv preprint arXiv:2106.03253},
  year={2021}
}

@article{kadra2021tabular,
  title={Regularization is all you Need: Simple Neural Nets can Excel on Tabular Data},
  author={Kadra, Arlind and Lindauer, Marius and Hutter, Frank and Grabocka, Josif},
  journal={arXiv preprint arXiv:2106.11189},
  year={2021}
}


@article{gorishniy2021tabular,
  title={Revisiting Deep Learning Models for Tabular Data},
  author={Gorishniy, Yuri and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  journal={arXiv preprint arXiv:2106.11959},
  year={2021}
}

@article{gorishniy2022embeddings,
  title={On Embeddings for Numerical Features in Tabular Deep Learning},
  author={Gorishniy, Yura and Rubachev, Ivan and Babenko, Artem},
  journal={arXiv preprint arXiv:2203.05556},
  year={2022}
}

@article{somepalli2021saint,
  title={SAINT: Improved neural networks for tabular data via row attention and contrastive pre-training},
  author={Somepalli, Gowthami and Goldblum, Micah and Schwarzschild, Avi and Bruss, C Bayan and Goldstein, Tom},
  journal={arXiv preprint arXiv:2106.01342},
  year={2021}
}

@article{kossen2021self,
  title={Self-attention between datapoints: Going beyond individual input-output pairs in deep learning},
  author={Kossen, Jannik and Band, Neil and Lyle, Clare and Gomez, Aidan N and Rainforth, Thomas and Gal, Yarin},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
