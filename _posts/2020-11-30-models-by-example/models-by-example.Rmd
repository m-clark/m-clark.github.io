---
title: "Models by Example"
description: |
  Roll your own to understand more.
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '`r format(Sys.Date(), "%B %d, %Y")`'
preview: ../../img/gp.svg 
output:
  distill::distill_article:
    self_contained: false
    toc: false
    css: ../../styles.css
draft: false
twitter:
  site: "@statsdatasci"
  creator: "@statsdatasci"
tags: [R, Python, Julia, Matlab, algorithms, bayesian, neural network, linear regression, lasso, pca, expectation maximization, splines, logistic regression, gradient descent, rkhs, ridge regression, cox, hamiltonian monte carlo, mixed models, penalized regression, maximum likelihood estimation, tobit, multinomial, ordinal, zero inflated, marginal structural models]
categories:
  - regression
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo      = T, 
  message   = F, 
  warning   = F, 
  comment   = NA,
  R.options = list(width = 120),
  cache.rebuild = F,
  cache = T,
  fig.align = 'center',
  fig.asp = .7,
  dev = 'svg',
  dev.args = list(bg = 'transparent')
)

library(tidyverse)
library(broom)
library(kableExtra)
library(visibly)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}

rnd = tidyext::rnd
```




# New Book

I've completed a new bookdown document, [Models by Example](https://m-clark.github.io/models-by-example/), that converts most of the code from my Miscellaneous R repo.  I initially just wanted to update the code, but decided to use a more formal approach to make it cleaner and more accessible.  It's mostly complete, though may be added to on rare occasion, and further cleaned as I find annoying bits here and there.  Each topic contains 'by-hand' demonstration, such that you can see conceptually how a model is estimated, or technique employed. This can help those that want to dive a little deeper to get a peek behind the curtain of the functions and packages they use, hopefully empowering them to go further with such models.

Topics covered include the following, and I plan to post a sample chapter soon.

##### Models

- Linear Regression
- Logistic Regression
- One-factor Mixed Model
- Two-factor Mixed Model
- Mixed Model via ML
- Probit & Bivariate Probit
- Heckman Selection
- Marginal Structural Model
- Tobit
- Cox Survival
- Hurdle Model
- Zero-Inflated Model
- Naive Bayes
- Multinomial
- Ordinal
- Markov Model
- Hidden Markov Model
- Quantile Regression
- Cubic Spline Model
- Gaussian Processes
- Neural Net
- Extreme Learning Machine
- Reproducing Kernel Hilbert Space Regression
- Confirmatory Factor Analysis

##### Bayesian

- Basics
- Bayesian t-test
- Bayesian Linear Regression
- Bayesian Beta Regression
- Bayesian Mixed Model
- Bayesian Multilevel Mediation
- Bayesian IRT
- Bayesian CFA
- Bayesian Nonparametric Models
- Bayesian Stochastic Volatility Model
- Bayesian Multinomial Models
- Variational Bayes Regression
- Topic Model

##### Estimation

- Maximum Likelihood
- Penalized Maximum Likelihood
- L1 (lasso) regularization
- L2 (ridge) regularization
- Newton and IRLS
- Nelder Mead
- Expectation-Maximization
- Gradient Descent
- Stochastic Gradient Descent
- Metropolis Hastings
- Hamiltonian Monte Carlo
