<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>Michael Clark: Practical Bayes Part II</title>

<meta property="description" itemprop="description" content="Taking a better approach and avoiding issues."/>

<link rel="canonical" href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"/>
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"/>
<link rel="icon" type="image/vnd.microsoft.icon" href="../../img/favicon.ico"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2021-02-28"/>
<meta property="article:created" itemprop="dateCreated" content="2021-02-28"/>
<meta name="article:author" content="Michael Clark"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Michael Clark: Practical Bayes Part II"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Taking a better approach and avoiding issues."/>
<meta property="og:url" content="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"/>
<meta property="og:image" content="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/../../img/r_and_stan.png"/>
<meta property="og:image:width" content="816"/>
<meta property="og:image:height" content="303"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Michael Clark"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Michael Clark: Practical Bayes Part II"/>
<meta property="twitter:description" content="Taking a better approach and avoiding issues."/>
<meta property="twitter:url" content="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"/>
<meta property="twitter:image" content="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/../../img/r_and_stan.png"/>
<meta property="twitter:image:width" content="816"/>
<meta property="twitter:image:height" content="303"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Michael Clark: Practical Bayes Part II"/>
<meta name="citation_fulltext_html_url" content="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2021/02/28"/>
<meta name="citation_publication_date" content="2021/02/28"/>
<meta name="citation_author" content="Michael Clark"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","date","preview","output","draft","tags","categories","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY-SA"]},{"type":"character","attributes":{},"value":["Practical Bayes Part II"]},{"type":"character","attributes":{},"value":["Taking a better approach and avoiding issues."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["February 28, 2021"]},{"type":"character","attributes":{},"value":["../../img/r_and_stan.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../styles.css","https://use.fontawesome.com/releases/v5.14.0/css/all.css"]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["bayesian","stan","<span class=\"pack\" style = \"\">rstanarm<\/span>","brms","errors","warnings","posterior predictive checks","model averaging","loo","waic"]},{"type":"character","attributes":{},"value":["bayesian"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["practical-bayes-part-ii_files/anchor-4.2.2/anchor.min.js","practical-bayes-part-ii_files/bowser-1.9.3/bowser.min.js","practical-bayes-part-ii_files/crosstalk-1.1.1/css/crosstalk.css","practical-bayes-part-ii_files/crosstalk-1.1.1/js/crosstalk.js","practical-bayes-part-ii_files/crosstalk-1.1.1/js/crosstalk.js.map","practical-bayes-part-ii_files/crosstalk-1.1.1/js/crosstalk.min.js","practical-bayes-part-ii_files/crosstalk-1.1.1/js/crosstalk.min.js.map","practical-bayes-part-ii_files/datatables-binding-0.17/datatables.js","practical-bayes-part-ii_files/datatables-css-0.0.0/datatables-crosstalk.css","practical-bayes-part-ii_files/distill-2.2.21/template.v2.js","practical-bayes-part-ii_files/dt-core-1.10.20/css/jquery.dataTables.extra.css","practical-bayes-part-ii_files/dt-core-1.10.20/css/jquery.dataTables.min.css","practical-bayes-part-ii_files/dt-core-1.10.20/js/jquery.dataTables.min.js","practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-1.svg","practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-2.svg","practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-show-1.svg","practical-bayes-part-ii_files/figure-html5/cv-feature-select-mcmc-area-1.svg","practical-bayes-part-ii_files/figure-html5/cv-feature-selection-show-1.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-1.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-2.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-med-max-1.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-med-max-2.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-re-1.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-summary-plots-1.svg","practical-bayes-part-ii_files/figure-html5/model-baseline-summary-plots-2.svg","practical-bayes-part-ii_files/figure-html5/model-start-explore-1.svg","practical-bayes-part-ii_files/figure-html5/proposed-priors-plot-1.svg","practical-bayes-part-ii_files/figure-html5/r2-not-pp-check-1.svg","practical-bayes-part-ii_files/figure-html5/tidybayesdemo-1.svg","practical-bayes-part-ii_files/header-attrs-2.6/header-attrs.js","practical-bayes-part-ii_files/htmlwidgets-1.5.3/htmlwidgets.js","practical-bayes-part-ii_files/jquery-3.5.1/jquery-AUTHORS.txt","practical-bayes-part-ii_files/jquery-3.5.1/jquery.js","practical-bayes-part-ii_files/jquery-3.5.1/jquery.min.js","practical-bayes-part-ii_files/jquery-3.5.1/jquery.min.map","practical-bayes-part-ii_files/kePrint-0.0.1/kePrint.js","practical-bayes-part-ii_files/lightable-0.0.1/lightable.css","practical-bayes-part-ii_files/popper-2.6.0/popper.min.js","practical-bayes-part-ii_files/tippy-6.2.7/tippy-bundle.umd.min.js","practical-bayes-part-ii_files/tippy-6.2.7/tippy-light-border.css","practical-bayes-part-ii_files/tippy-6.2.7/tippy.css","practical-bayes-part-ii_files/tippy-6.2.7/tippy.umd.min.js","practical-bayes-part-ii_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.6/header-attrs.js"></script>
  <script src="../../site_libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
  <script src="../../site_libs/jquery-3.5.1/jquery.min.js"></script>
  <link href="../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
  <script src="../../site_libs/datatables-binding-0.17/datatables.js"></script>
  <link href="../../site_libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
  <link href="../../site_libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
  <script src="../../site_libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
  <link href="../../site_libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
  <script src="../../site_libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
  <script src="../../site_libs/kePrint-0.0.1/kePrint.js"></script>
  <link href="../../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-79528685-1"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-79528685-1');
</script>
<style type="text/css">
@import url("pygment_highlights.css");
@import url(https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
@import url("https://fonts.googleapis.com/css?family=Roboto|Roboto+Mono|Roboto+Condensed|Open+Sans|Open+Sans+Condensed:300|Open+Sans+Condensed:light|Lato|Lora|Fira+Sans|Fira+Mono");


body {
  font-family: Roboto, 'Libre Baskerville', sans-serif; /*, et-book, "Palatino Linotype", "Palatino LT STD", 'Lora', serif*/
  font-size: 15px;
  font-weight: 300;
  color: #404040;        /* #404040*/
  position: relative;
  background: #FFFFF8;      /* {{ site.page-col }}; */
}

/* distill specific */

d-title h1 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-weight: 200;
  font-size: 50px;
  color: #ff5500;
  margin-top: 4rem;
  margin-bottom: 1.5rem;
  line-height: 1;
}

.index-title h1 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-weight: 200;
  font-size: 75px;
  font-variant: small-caps;
  text-align: center;
  color: #ff5500;
  margin-top: 4rem;
  margin-bottom: 1.5rem;
  line-height: 1;
  border-bottom: 0; /*same as default h2*/
  padding-bottom: 1rem; 
}

d-article h1 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-style: normal;
  font-variant: small-caps;
  font-weight: 400;
  font-size: 175%;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1); /*same as default h2*/
  padding-bottom: 1rem;
}

d-article h2 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-style: normal;
  font-weight: 400;
  font-size: 150%;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
  /* to remove will require something to keep the inline from inserting */
  border-bottom: 0px solid rgba(0, 0, 0, 0.1); 
  padding-bottom: 1rem; 
  
}


d-article h3 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-style: normal;
  font-weight: 400;
  font-size: 125%;
  color: #ff5500;
  opacity: .9;
  margin-top: 2rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

d-article  h4 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-style: normal;
  text-transform: none;  /*default is uppercase*/
  font-weight: 400;
  font-size: 110%;
  color: #ff5500;
  opacity: .9;
  margin-top: 1.9rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

d-article  h5 {
  font-family: 'Open Sans Condensed', Roboto, Helvetica, Arial, sans;
  font-style: normal;
  text-transform: none;  /*default is uppercase*/
  font-weight: 400;
  font-size: 100%;
  color: #ff5500;
  opacity: .9;
  margin-top: 1.9rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}



/* Nav bar */

.distill-site-nav {
  color: #404040;
  background-color: #d9edf7;
  font-size: 20px;
  font-weight: 300;
}


.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: #0085a1;
}

/* sidebar on front page with category listing */

.posts-with-sidebar .posts-sidebar {
  float: right;
  width: 10%;    /* default 20, made narrow */
  margin-top: 60px;
  padding-top: 24px;
  padding-bottom: 24px;
}

/* attempt to make result not so wide/spacious */ 

.posts-with-sidebar .posts-list {
  width: 66%;
  margin-left: 11%;
}

.posts-sidebar {
  font-size: 75%;
  margin-right: 10%;
}


/* code */

/* will now work as of latest distill version*/

d-article div.sourceCode code, d-article pre code {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  color: #404040FF;
  font-size: 90%;
}


d-article pre {
  background-color: #FFFFF8;
}

/* Otherwise will leave a white background visible at bottom of code chunks*/
d-article div.sourceCode {
  background-color: #FFFFF8;
}

/* code results/output */
pre.text-output {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  color: #000000CC;
}



/* latex */
.math {
  color: #404040;  
  font-weight: normal;
  font-size: 90%;
}


/* link effects; appendix apply to footnote return links */

/*remove old line*/
d-article a:hover {
  text-decoration: none;
  border-bottom: none;
  background-size: 100% 100%;
  cursor: pointer;
}


/* add new effects */
p a, aside a, li a, d-appendix a, a.footnote-backlink {
    color: #03b3ff;
    display: inline-block;
    text-decoration: none;
    transition: background-size .4s ease;
    border-bottom: 0px solid;
}

p a {
  /* text-decoration: underline */
  color: #03b3ff;
}

p a:after, aside a:after, li a:after, d-appendix a:after {
    content: '';
    display: block;
    width: 0;
    height: 1.25px;
    background: #FF4F03;
    transition: width .3s;
}

p a:hover::after, aside a:hover::after, li a:hover::after, d-appendix a:hover::after {
  width: 100%;
  //transition: width .3s;
 }

/* for twitter etc icon links */
.social-icon {
  color: #03b3ff;
  background-image: none;  /* remove hover line*/
  background-size: 0 100%;
  background-repeat: no-repeat;
  text-decoration: none;
  transition: background-size .4s ease;
  border-bottom: 0px solid;
}

d-footnote-list a.footnote-backlink {
    color:  #03b3ff !important; /* otherwise some inline injection will occur*/
    padding-left: 0.5em;
}

.categories li > a:hover {
  border-bottom: none !important;
}

/* remove underline for TOC */
.d-contents nav a:hover {
    text-decoration: none;
}



/* text highlights */
.emph, em {
  color: #E32D00;  /*#ff5500 #D14300*/
  font-style: normal;
  font-weight: 450;
}

/* don't do color for references */
.references em {
  color: rgba(0,0,0,0.5);
  font-style: normal;
  font-weight: 450;
}

strong {
  color: #404040;  
}

/* pack func and objclass colors initially come from hcl(seq(90,360, length.out=4), c=80, l=80); redone for contrast*/
.pack {
  color: #1f65b7; /* #990071 #AC9CFF #e41a1c*/
  font-weight: 400;
}

.func {
  color: #007020;   /*#007199 #00CBB6; #984ea3; can just use `` instead*/
  font-weight: 400;
}

.objclass {
  color:  #947100;  /*#AAB400 #4daf4a; #FFC5D0*/
  font-weight: 400;
}

/* object/class via inline code */
p code {
  color: #947100;
}


/* figures and tables */

d-article table {
    border-collapse: collapse;
    margin-top: 20px;
    margin-bottom: 20px;
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

/* add spacing for figs and tables, so text and other figs/tables don't 
start right up at their border */
.l-body {
  margin-top: 20px;
  margin-bottom: 20px;
}

/* Search bar */

.algolia-autocomplete {
    display: inline-block;
    margin-left: 10px;
    vertical-align: sub;
    background-color: #fffff8;
    color: #03b3ff;             /* Color of text in drop-down*/
    padding: 6px;
    padding-top: 8px;
    padding-bottom: 0;
    border-radius: 6px;
    border: 0px #03b3ff solid;  /* Removed border */
    width: 180px;
}
</style>
<!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../styles.css" type="text/css"/>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Practical Bayes Part II","description":"Taking a better approach and avoiding issues.","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-02-28T00:00:00.000+00:00","citationText":"Clark, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a class="logo" href="../../index.html">
<img src="../../img/mc_logo.png" alt="Logo"/>
</a>
<a href="../../index.html" class="title">Michael Clark</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../about.html">About</a>
<a href="../../documents.html">Documents</a>
<a href="../../workshops.html">Workshops</a>
<a href="../../code.html">Code</a>
<a href="../../resources.html">Resources</a>
<a href="https://github.com/m-clark">
<i class="fab fa-github-alt fa-1x" aria-hidden="true"></i>
</a>
<a href="../../index.xml">
<i class="fa fa-rss fa-1x" aria-hidden="true"></i>
</a>
<a href="https://twitter.com/statsdatasci">
<i class="fab fa-twitter fa-1x" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Practical Bayes Part II</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:bayesian" class="dt-tag">bayesian</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>Taking a better approach and avoiding issues.</p></p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>February 28, 2021
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#overview">Overview</a>
<ul>
<li><a href="#outline-for-better-bayesian-analysis">Outline for Better Bayesian Analysis</a></li>
</ul></li>
<li><a href="#example-data">Example data</a></li>
<li><a href="#simulate-from-priors">Simulate from priors</a></li>
<li><a href="#summarizing-a-model">Summarizing a Model</a>
<ul>
<li><a href="#check-priors">Check Priors</a></li>
<li><a href="#explore-and-visualize-results">Explore and Visualize Results</a></li>
<li><a href="#model-effectiveness">Model Effectiveness</a>
<ul>
<li><a href="#posterior-predictive-checks">Posterior predictive checks</a></li>
<li><a href="#bayes-r-squared">Bayes R-squared</a></li>
</ul></li>
</ul></li>
<li><a href="#prediction-model-comparison">Prediction &amp; Model Comparison</a>
<ul>
<li><a href="#basic-prediction">Basic prediction</a></li>
<li><a href="#model-comparison">Model Comparison</a>
<ul>
<li><a href="#choosing-a-model">Choosing a model</a></li>
<li><a href="#problems-at-the-loo">Problems at the loo</a></li>
</ul></li>
<li><a href="#model-averaging">Model Averaging</a></li>
<li><a href="#cross-validation">Cross-Validation</a>
<ul>
<li><a href="#variable-selection">Variable Selection</a></li>
</ul></li>
<li><a href="#the-rabbit-hole-of-model-comparsion">The rabbit hole of model comparsion</a></li>
<li><a href="#solutions-for-model-comparison">Solutions for Model Comparison</a></li>
</ul></li>
<li><a href="#summary-the-practical-approach-to-bayesian-models">Summary: The Practical Approach to Bayesian Models</a></li>
<li><a href="#resources">Resources</a>
<ul>
<li><a href="#prior-checks">Prior Checks</a></li>
<li><a href="#r2">R<sup>2</sup></a></li>
<li><a href="#model-comparison-1">Model Comparison</a></li>
<li><a href="#pareto-values-1">Pareto values</a></li>
<li><a href="#model-averaging-1">Model Averaging</a></li>
<li><a href="#cross-validation-1">Cross-Validation</a></li>
<li><a href="#misc">Misc</a></li>
</ul></li>
</ul>
</nav>
</div>
<h1 id="overview">Overview</h1>
<p>In <a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">Part I</a>, we talked about the basics one can do to run a Bayesian model with a high-level Stan package like <span class="pack" style="">brms</span>, and what to do if there is a problem. But it might be nice if we could take steps to avoid the problems in the first place, and what’s more, our model might still be inadequate without any warnings, and we’ll still need to inspect diagnostics regardless. So let’s engage in some better practices you can use every time to help things run more smoothly, and get more from your models after you’ve run them.</p>
<aside>
This is part two of two posts on doing practical modeling with R and Stan in an applied fashion. Due to unforeseen circumstances (and plenty of procrastination), the bulk of the content of these posts was created many months before actual posting. It’s hoped that most of this will still be applicable and have the conceptual continuity as originally intended, but apologies in advance if some parts seem a little disjointed, off topic, etc.
</aside>
<h2 id="outline-for-better-bayesian-analysis">Outline for Better Bayesian Analysis</h2>
<p>We’ll cover the following steps in more detail, but here is a general outline.</p>
<ul>
<li>First generate ‘fake data’ to assess viability of our priors</li>
<li>With adequate priors, start with a simple, but plausible model</li>
<li>For simple models you likely do not need many iterations, and for debugging/troubleshooting, starting with few iterations can possibly give you a sense of whether there will be problems<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. If you are doing standard GLM or simpler versions of common extensions, even the defaults are likely overkill. For example, a basic linear regression should converge almost immediately.</li>
<li>If you have problems at this point, see <a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">Part I</a></li>
</ul>
<ul>
<li>Explore and Visualize the Model Results
<ul>
<li>Visualize covariate relationships</li>
<li>Assess model effectiveness
<ul>
<li>Use posterior predictive checks</li>
<li>Other avenues</li>
</ul></li>
</ul></li>
<li>Prediction and Model Comparisons
<ul>
<li>Get basic predictions for observations of interest</li>
<li>Explore a more viable model
<ul>
<li>Add interactions</li>
<li>Add nonlinear relations</li>
<li>Account for other structure (e.g. random effects)</li>
</ul></li>
<li>Compare and/or average models</li>
<li>Use cross-validation to better assess performance</li>
</ul></li>
</ul>
<p>We’ll now demonstrate these steps.</p>
<h1 id="example-data">Example data</h1>
<p><a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">As in Part I</a>, I’m going to create some data for us to run some basic models with, the same as Part I. As a reminder, the true underlying model has categorical and continuous covariates, interactions, nonlinear relationships, random effects (observations are clustered in groups), and some variables are collinear.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>For our purposes so we’ll create a data frame with the total sample size of 1000.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># create the primary data frame</span>

<span class='va'>main_df</span> <span class='op'>=</span> 
  <span class='fu'>create_data</span><span class='op'>(</span>N <span class='op'>=</span> <span class='fl'>1000</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>select</span><span class='op'>(</span><span class='va'>group</span>, <span class='va'>b1</span><span class='op'>:</span><span class='va'>x3</span>, <span class='va'>y</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>mutate</span><span class='op'>(</span>
    b1 <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span><span class='op'>(</span><span class='va'>b1</span><span class='op'>)</span>,   <span class='co'># will help with visuals</span>
    b2 <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span><span class='op'>(</span><span class='va'>b2</span><span class='op'>)</span>
  <span class='op'>)</span>
</code></pre>
</div>
</div>
<h1 id="simulate-from-priors">Simulate from priors</h1>
<p>A good initial step in Bayesian analysis is to think about and produce some viable priors for the parameters. But the obvious question is, what priors should we choose? Thankfully, for standard models there is not much guesswork involved. Bayesian analysis has been around a long time, so the bulk of the work in determining suitable priors for standard models has been done for you. Even default settings should not affect things much, especially for <span class="pack" style="">rstanarm</span>, which has some basic defaults that are informed by the data. However, due to the flexibility of the <span class="pack" style="">brms</span> modeling functions, some priors are unspecified and left ‘flat’ (i.e. uniform), which is something we definitely don’t want. And even defaults could still cause problems for more complex situations. So how might we choose better ones?</p>
<p>The basic idea here is to generate parameters (e.g. regression coefficients) based on their corresponding prior distributions, predict data based on those prior draws, and then compare the predictions to our observed target variable that we are attempting to understand.</p>
<p>Thankfully, the <span class="pack" style="">brms</span> package makes this very easy to do. We will check the following types of priors, that range from default settings to increasing specification for all parameters of interest.</p>
<div class="layout-chunk" data-layout="l-body">
<div id="htmlwidget-b00327701f375583695d" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b00327701f375583695d">{"x":{"filter":"none","data":[["Note:","Regression coefficients:","Intercept:","Variances:"],["similar to brms","uniform","default","default"],["similar to rstanarm","normal, diffuse","default","default"],["similar to rstanarm","normal","default","default"],["If data is standardized, this would be very reasonable","Normal(0, 1)","default","default"],["restricts range of intercept to more plausible values","Normal(0, 1)","mean of `y` (~3)","default"],["restricts range of sigma to more plausible values","Normal(0, 1)","based on mean of `y` (~3)","based on sd of `y` (~1)"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Prior set 0<\/th>\n      <th>Prior set 1<\/th>\n      <th>Prior set 2<\/th>\n      <th>Prior set 3<\/th>\n      <th>Prior set 4<\/th>\n      <th>Prior set 5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","autoWidth":true,"columnDefs":[{"targets":"","orderable":false},{"orderable":false,"targets":0}],"scrollX":true,"order":[],"orderClasses":false,"rowCallback":"function(row, data) {\nvar value=data[-1]; $(this.api().cell(row, -1).node()).css({'white-space':'nowrap'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'white-space':'nowrap'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'white-space':'nowrap'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'white-space':'nowrap'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'white-space':'nowrap'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'white-space':'nowrap'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'white-space':'nowrap'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-weight':'bold','text-align':'left'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
</div>
<p>We can use <span class="func" style="">pp_check</span> to examine the prior-generated data versus the observed target <code>y</code>, but I wait to show them all together at the end. Note the argument <code>sample_prior</code>, which we set to <code>'only'</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/paul-buerkner/brms'>brms</a></span><span class='op'>)</span>

<span class='co'># essentially the same as the defaults</span>
<span class='va'>pr_uniform</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>uniform</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>100</span>, <span class='fl'>100</span><span class='op'>)</span>, lb <span class='op'>=</span> <span class='op'>-</span><span class='fl'>100</span>, ub <span class='op'>=</span> <span class='fl'>100</span>, <span class='st'>'b'</span><span class='op'>)</span>

<span class='va'>model_default_prior</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_uniform</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_default_prior, nsamples = 50)</span>

<span class='co'># diffuse normal for reg coefficients 'b'</span>
<span class='va'>pr_norm_b_0_10</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>10</span><span class='op'>)</span>, <span class='st'>'b'</span><span class='op'>)</span>

<span class='va'>model_0_norm_b_0_10</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_norm_b_0_10</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_0_norm_b_0_10, nsamples = 50)</span>

<span class='co'># rstanarm-like prior</span>
<span class='va'>pr_auto</span> <span class='op'>=</span> <span class='fu'>sjstats</span><span class='fu'>::</span><span class='fu'><a href='https://strengejacke.github.io/sjstats/reference/auto_prior.html'>auto_prior</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>,
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  gaussian <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>

<span class='va'>model_auto_prior</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_auto</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_auto_prior, nsamples = 50)</span>

<span class='co'># Since we have standardized data, Normal(0, 1) is reasonable for reg coefs</span>
<span class='va'>pr_norm_b_0_1</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, <span class='st'>'b'</span><span class='op'>)</span>

<span class='va'>model_0_norm_b_0_1</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_norm_b_0_1</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_0_norm_b_0_1, nsamples = 50)</span>

<span class='co'># Now we add one for the intercept based on the mean of y</span>
<span class='va'>pr_norm_b_norm_int</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'b'</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'Intercept'</span><span class='op'>)</span>
<span class='op'>)</span>

<span class='va'>model_0_norm_b_0_1_norm_Int</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_norm_b_norm_int</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_0_norm_b_0_1_norm_Int, nsamples = 50)</span>

<span class='co'># Now add a prior for sigma based on the sd of y</span>
<span class='va'>pr_norm_b_norm_int_t_sigma</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'b'</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'Intercept'</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>10</span>, <span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'sigma'</span><span class='op'>)</span> <span class='co'># first value is deg of freedom</span>
<span class='op'>)</span>

<span class='va'>model_0_norm_b_0_1_norm_Int_sigma</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span>, 
  data <span class='op'>=</span> <span class='va'>main_df</span>,
  iter <span class='op'>=</span> <span class='fl'>1000</span>,
  sample_prior <span class='op'>=</span> <span class='st'>'only'</span>,
  prior <span class='op'>=</span> <span class='va'>pr_norm_b_norm_int_t_sigma</span>
<span class='op'>)</span>

<span class='co'># pp_check(model_0_norm_b_0_1_norm_Int_sigma, nsamples = 50)</span>
</code></pre>
</div>
</div>
<p>The following plot shows the model predictions based on priors only. We restrict the range of values for display purposes, so note that some of these settings would actually generate more extreme results. For example, the default prior setting could generate values into the <span class="math inline">\(\pm\)</span> 500 and beyond. I also mark the boundaries of the observed target variable with the vertical lines.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="practical-bayes-part-ii_files/figure-html5/proposed-priors-plot-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>We can see in the visualization that the left side using defaults or notably diffuse priors results in nonsensical ranges for our target variable. When we actually run the model, this means we’d explore possible (the space of) parameter values that aren’t going to be useful for prediction. We would likely still should come to the same conclusions, it’s just that we might need many more iterations, and as we know from <a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">Part I</a>, not having enough iterations can lead to many warnings.</p>
<p>So given that our target variable is between -2 and 8, it seems that just adding some basic, data-informed information to our priors resulted in more plausible results. This will generally help our models be more efficient and better behaved. Note that if all else fails, you can use a convenience function like <span class="func" style="">auto_prior</span> demonstrated above.</p>
<h1 id="summarizing-a-model">Summarizing a Model</h1>
<p>Now let’s run a baseline model, one that’s simple but plausible. Given that there will eventually be other complexities added to the model, I’ll go ahead and add some iterations, and increase <code>adapt_delta</code> and <code>max_treedepth</code> now to make the code reusable.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/paul-buerkner/brms'>brms</a></span><span class='op'>)</span>

<span class='va'>pr</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>normal</span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'b'</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>10</span>, <span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'sigma'</span><span class='op'>)</span>,
  <span class='fu'><a href='https://rdrr.io/pkg/brms/man/set_prior.html'>prior</a></span><span class='op'>(</span><span class='fu'>student_t</span><span class='op'>(</span><span class='fl'>10</span>, <span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>, class <span class='op'>=</span> <span class='st'>'sd'</span><span class='op'>)</span>  <span class='co'># prior for random intercept std dev</span>
<span class='op'>)</span>

<span class='va'>model_baseline</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/brm.html'>brm</a></span><span class='op'>(</span>
  <span class='va'>y</span> <span class='op'>~</span> <span class='va'>b1</span> <span class='op'>+</span> <span class='va'>b2</span> <span class='op'>+</span> <span class='va'>x1</span> <span class='op'>+</span> <span class='va'>x2</span> <span class='op'>+</span> <span class='va'>x3</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>|</span> <span class='va'>group</span><span class='op'>)</span>, 
  data    <span class='op'>=</span> <span class='va'>main_df</span>,
  warmup  <span class='op'>=</span> <span class='fl'>5000</span>,
  iter    <span class='op'>=</span> <span class='fl'>6000</span>,
  thin    <span class='op'>=</span> <span class='fl'>4</span>,
  prior   <span class='op'>=</span> <span class='va'>pr</span>, 
  cores   <span class='op'>=</span> <span class='fl'>4</span>,
  seed    <span class='op'>=</span> <span class='fl'>1234</span>, 
  control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>
    adapt_delta   <span class='op'>=</span> <span class='fl'>.95</span>,
    max_treedepth <span class='op'>=</span> <span class='fl'>15</span>
  <span class='op'>)</span>,
  save_pars <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/save_pars.html'>save_pars</a></span><span class='op'>(</span>all <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>  <span class='co'># potentially allows for more  more post-processing functionality</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: y ~ b1 + b2 + x1 + x2 + x3 + (1 | group) 
   Data: main_df (Number of observations: 1000) 
Samples: 4 chains, each with iter = 6000; warmup = 5000; thin = 4;
         total post-warmup samples = 1000

Group-Level Effects: 
~group (Number of levels: 100) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     0.87      0.07     0.74     1.03 1.00      771      762

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     2.69      0.21     2.28     3.12 1.01      788      687
b11           0.80      0.07     0.66     0.93 1.00      935      955
b21          -0.15      0.19    -0.51     0.23 1.01      900      931
x1            0.04      0.04    -0.03     0.11 1.00      861      891
x2           -0.03      0.04    -0.11     0.04 1.00      937      903
x3            0.27      0.04     0.20     0.34 1.00      823      975

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     1.03      0.02     0.99     1.08 1.00      998      988

Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<p>For reporting purposes, generally all you need are the <code>Estimate</code> and lower and upper bounds. You might also mention that the basic diagnostics suggested no problems, but you’ll still want to explore this a bit for yourself (as in <a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">Part I</a>). If you want a visual approach to these basic results, you can use something like the following types of plots.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/mcmc_plot.brmsfit.html'>mcmc_plot</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, type <span class='op'>=</span> <span class='st'>'areas'</span><span class='op'>)</span>
</code></pre>
</div>
<img src="practical-bayes-part-ii_files/figure-html5/model-baseline-summary-plots-1.svg" width="624" style="display: block; margin: auto;" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/mcmc_plot.brmsfit.html'>mcmc_plot</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, type <span class='op'>=</span> <span class='st'>'intervals'</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/model-baseline-summary-plots-2.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>The <span class="pack" style="">tidybayes</span> package offers some nice options as well. It takes a bit of getting used to, but can be very handy. As an example, the following gives a visual sense of the probability of regression coefficient values beyond a chosen point of interest, in this case, arbitrarily chosen as <code>abs(.25)</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://mjskay.github.io/tidybayes/'>tidybayes</a></span><span class='op'>)</span>

<span class='co'># get_variables(model_baseline) %&gt;% as_tibble() # to see variable names as required for plotting.</span>

<span class='co'># grab fixed effects - intercept</span>
<span class='va'>tidy_plot_data_fe</span> <span class='op'>=</span> <span class='va'>model_baseline</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='http://mjskay.github.io/tidybayes/reference/spread_draws.html'>spread_draws</a></span><span class='op'>(</span><span class='va'>`^b_(b|x).*`</span>, regex <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>pivot_longer</span><span class='op'>(</span><span class='va'>b_b11</span><span class='op'>:</span><span class='va'>b_x3</span>, names_to <span class='op'>=</span> <span class='st'>'coefficient'</span><span class='op'>)</span>

<span class='va'>tidy_plot_data_fe</span> <span class='op'>%&gt;%</span>
  <span class='fu'>ggplot</span><span class='op'>(</span><span class='fu'>aes</span><span class='op'>(</span>y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rev.html'>rev</a></span><span class='op'>(</span><span class='va'>coefficient</span><span class='op'>)</span>, x <span class='op'>=</span> <span class='va'>value</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>geom_vline</span><span class='op'>(</span>xintercept <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>.25</span>, <span class='fl'>.25</span><span class='op'>)</span>, color <span class='op'>=</span> <span class='st'>'gray92'</span>, size <span class='op'>=</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='http://mjskay.github.io/ggdist/reference/geom_dotsinterval.html'>stat_dotsinterval</a></span><span class='op'>(</span>
    <span class='fu'>aes</span><span class='op'>(</span>fill <span class='op'>=</span> <span class='fu'>stat</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>&lt;</span> <span class='fl'>.25</span><span class='op'>)</span><span class='op'>)</span>,
    quantiles <span class='op'>=</span> <span class='fl'>40</span>,
    point_color <span class='op'>=</span> <span class='st'>'#b2001d'</span>,
    interval_color <span class='op'>=</span> <span class='st'>'#b2001d'</span>,
    interval_alpha <span class='op'>=</span> <span class='fl'>.6</span>
  <span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>scico</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/scico/man/ggplot2-scales.html'>scale_fill_scico_d</a></span><span class='op'>(</span>begin <span class='op'>=</span> <span class='fl'>.2</span>, end <span class='op'>=</span> <span class='fl'>.6</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>labs</span><span class='op'>(</span>y <span class='op'>=</span> <span class='st'>''</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>guides</span><span class='op'>(</span>fill <span class='op'>=</span> <span class='st'>'none'</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/pkg/visibly/man/theme_clean.html'>theme_clean</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/tidybayesdemo-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="check-priors">Check Priors</h2>
<p>Though we did some work to select our prior distributions beforehand, we might still be concerned about how influential our priors were. So how can we check whether our priors were informative? The following uses the <span class="pack" style="">bayestestR</span> package to do a simple check of whether the posterior standard deviation is greater than 10% of the prior standard deviation<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Having an informative prior isn’t really a problem in my opinion, unless it’s more informative than you wanted. For example, shrinkage of a coefficient towards zero will generally help avoid overfitting.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/prior_summary.brmsfit.html'>prior_summary</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>                  prior     class      coef group resp dpar nlpar bound       source
           normal(0, 1)         b                                               user
           normal(0, 1)         b       b11                             (vectorized)
           normal(0, 1)         b       b21                             (vectorized)
           normal(0, 1)         b        x1                             (vectorized)
           normal(0, 1)         b        x2                             (vectorized)
           normal(0, 1)         b        x3                             (vectorized)
 student_t(3, 2.9, 2.5) Intercept                                            default
    student_t(10, 1, 1)        sd                                               user
    student_t(10, 1, 1)        sd           group                       (vectorized)
    student_t(10, 1, 1)        sd Intercept group                       (vectorized)
    student_t(10, 1, 1)     sigma                                               user</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>bayestestR</span><span class='fu'>::</span><span class='fu'><a href='https://easystats.github.io/bayestestR/reference/check_prior.html'>check_prior</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>    Parameter Prior_Quality
1 b_Intercept   informative
2       b_b11 uninformative
3       b_b21   informative
4        b_x1 uninformative
5        b_x2 uninformative
6        b_x3 uninformative</code></pre>
</div>
<p>These results suggest that we might be more informative, but for the intercept, which we largely aren’t too worried about, and for the factor that is highly unbalanced (<code>b2</code>), but which has no obvious solution. I personally would be fine with this result, especially since we took initial care in choosing these priors. If you really wanted to, you could change the priors that were informative.</p>
<h2 id="explore-and-visualize-results">Explore and Visualize Results</h2>
<p>Now that we are feeling pretty good about the results we have, we can explore the model further. We can plot covariate effects easily with <span class="pack" style="">brms</span>. The <span class="func" style="">conditional_effects</span> function is what we want here. I show results for one effect below. Without interactions or other things going, on they aren’t very interesting, but it’s a useful tool nonetheless. We’ll come back to this later.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/conditional_effects.brmsfit.html'>conditional_effects</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, <span class='st'>'b2'</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/model-start-explore-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>We can also use the <span class="func" style="">hypothesis</span> function to test for specific types of effects. By default they provide a one-sided probability and uncertainty interval. For starters, we can just duplicate what we saw in the previous summary for the <code>b2</code> effect. The only benefit is to easily obtain the one-sided p-value (e.g. that <code>b2</code> is less than zero) and the corresponding <em>evidence ratio</em>, which is just <code>p/(1-p)</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/hypothesis.brmsfit.html'>hypothesis</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, <span class='st'>'b21 &lt; 0'</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Hypothesis Tests for class b:
  Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star
1  (b21) &lt; 0    -0.15      0.19    -0.46     0.16       3.67      0.79     
---
&#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
&#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%;
for two-sided hypotheses, the value tested against lies outside the 95%-CI.
Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
</div>
<p>But we can really try anything, which is the power of this function. As an example, the following tests whether the combined effect of our categorical covariates is greater than twice the value of the <code>x1</code> effect<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/hypothesis.brmsfit.html'>hypothesis</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, <span class='st'>'abs(b11) + abs(b21) &gt; 2*x1'</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Hypothesis Tests for class b:
                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star
1 (abs(b11)+abs(b21... &gt; 0     0.91      0.17     0.65     1.21        Inf         1    *
---
&#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
&#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%;
for two-sided hypotheses, the value tested against lies outside the 95%-CI.
Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
</div>
<p>One should get used to whatever tools are available for further understanding covariate effects or other parameters. This will likely lead to some of the more interesting discussion of your findings, or at least, notably more interesting than a standard regression table.</p>
<h2 id="model-effectiveness">Model Effectiveness</h2>
<p>It is one thing to look at specific effects. but a natural question to ask is how useful our model actually is as a whole. This then suggests we need to know how to define such utility. Such an assessment definitely cannot be made with something like ‘statistical significance’. Science of any kind is nothing without prediction, so we we can start there.</p>
<h3 id="posterior-predictive-checks">Posterior predictive checks</h3>
<p>Posterior predictive checks are a key component of Bayesian analysis. The prior checks we did before are just a special case of this. Here we instead use the posterior distributions of parameters to generate the data, and compare this model-implied/synthetic data to what we actually observe. Doing so can give insight to where the model succeeds and fails.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>
</code></pre>
</div>
<img src="practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-1.svg" width="624" style="display: block; margin: auto;" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>10</span>, type <span class='op'>=</span><span class='st'>'error_scatter_avg'</span>, alpha <span class='op'>=</span> <span class='fl'>.1</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-2.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>In this case, we see good alignment between model and data, and no obvious pattern to the types of errors we are getting. It is often the case that we see that the model does not capture the most extreme values well, but that’s not terribly surprising. With simulated data, our situation is more pristine to begin with, but you generally can’t expect such a clean result in practice.</p>
<p>As an example, consider predictions with and without random effects. Including the cluster-specific effects for prediction appear to do better with the capturing the tails.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-re-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>We can use the same approach to look at specific statistical measures of interest. For example, the following suggests our model is pretty good at capturing the minimum value, but typically underestimates the maximum value, which we noted earlier, is not especially unexpected in practice, particularly with smaller sample data.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>100</span>, type <span class='op'>=</span><span class='st'>'stat'</span>, stat<span class='op'>=</span><span class='st'>'median'</span><span class='op'>)</span>
</code></pre>
</div>
<img src="practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-med-max-1.svg" width="624" style="display: block; margin: auto;" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>100</span>, type <span class='op'>=</span><span class='st'>'stat'</span>, stat <span class='op'>=</span> <span class='st'>'max'</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/model-baseline-ppcheck-med-max-2.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>We can define any function to use for our posterior predictive check. The following shows how to examine the 10th and 90th quantiles. Minimum and maximum values are unlikely to be captured very well due to their inherent variability, so looking at less extreme quantiles (e.g. 10<sup>th</sup> or 90<sup>th</sup> percentile) might be a better way to assess whether the model captures the tails of a distribution.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>q10</span> <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/stats/quantile.html'>quantile</a></span><span class='op'>(</span><span class='va'>y</span>, <span class='fl'>0.1</span><span class='op'>)</span>
<span class='va'>q90</span> <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/stats/quantile.html'>quantile</a></span><span class='op'>(</span><span class='va'>y</span>, <span class='fl'>0.9</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>100</span>, type <span class='op'>=</span><span class='st'>'stat'</span>, stat <span class='op'>=</span> <span class='st'>'q90'</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_check.brmsfit.html'>pp_check</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, nsamples <span class='op'>=</span> <span class='fl'>100</span>, type <span class='op'>=</span><span class='st'>'stat_2d'</span>, stat <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'q10'</span>, <span class='st'>'q90'</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h3 id="bayes-r-squared">Bayes R-squared</h3>
<p>In this modeling scenario, we can examine the amount of variance accounted for in the target variable by the covariates. I don’t really recommend this beyond linear models that assume a normal distribution for the target, but people like to report it. Conceptually, it is simply a (squared) correlation of fitted values with the observed target values, so can be seen as descriptive statistic. Since we are Bayesians, we also get a ready-made interval for it, as it is based on the posterior predictive distribution. But to stress the complexity in trying to assess this, in this mixed model we can obtain the result with the random effect included (conditional) or without (unconditional). Both are reasonable ways to express the statistic, but the one including the group effect naturally will be superior, assuming the group-level variance is notable in the first place.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/bayes_R2.brmsfit.html'>bayes_R2</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span>                   <span class='co'># random effects included</span>
</code></pre>
</div>
<pre><code>    Estimate  Est.Error     Q2.5     Q97.5
R2 0.4823852 0.01829985 0.446667 0.5163177</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/bayes_R2.brmsfit.html'>bayes_R2</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, re_formula <span class='op'>=</span> <span class='cn'>NA</span><span class='op'>)</span>  <span class='co'># random effects not included</span>
</code></pre>
</div>
<pre><code>   Estimate  Est.Error       Q2.5     Q97.5
R2 0.116369 0.01448987 0.08753375 0.1446644</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># performance::r2_bayes(model_baseline)    # performance package provides both</span>
</code></pre>
</div>
</div>
<p>To show the limitation of R<sup>2</sup>, I rerun the model using a restrictive prior on the intercept. Intercepts for the resulting models are different but the other fixed effects are basically the same. The R<sup>2</sup> suggests equal performance of both models.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
R2
</th>
<th style="text-align:right;">
Est.Error
</th>
<th style="text-align:right;">
Q2.5
</th>
<th style="text-align:right;">
Q97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
baseline
</td>
<td style="text-align:right;">
0.116
</td>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
0.088
</td>
<td style="text-align:right;">
0.145
</td>
</tr>
<tr>
<td style="text-align:left;">
modified
</td>
<td style="text-align:right;">
0.116
</td>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
0.089
</td>
<td style="text-align:right;">
0.144
</td>
</tr>
</tbody>
</table>
</div>
<p>However, a posterior predictive check shows clearly the failure of the modified model to capture the data.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="practical-bayes-part-ii_files/figure-html5/r2-not-pp-check-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>A variant of R<sup>2</sup>, the ‘LOO’ R<sup>2</sup>, is also available via the <span class="func" style="">loo_R2</span> function. LOO stands for <em>leave-one-out</em>, as in leave-one-out cross-validation. It’s based on the residuals from the leave one out predictions. You can think of it as a better way to obtain an adjusted R<sup>2</sup> in this setting. The results suggests that the LOO R<sup>2</sup> actually picks up the difference in models, and would be lower for the modified model, even if we included the random effects.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>For more on Bayesian R<sup>2</sup>, see the <a href="#r2">resources section</a></p>
<h1 id="prediction-model-comparison">Prediction &amp; Model Comparison</h1>
<p>In general, a model is judged most by whether it has practical value. Even if we think a model is effective, there still might be another model that can do better. So it can be a good idea to have a couple of models to compare with one another. And one of the best ways to compare them is via prediction, especially by predicting on data the model wasn’t trained on to begin with.</p>
<p>For our demonstration, we will add two new models. The first adds interactions, the second adds a nonlinear relationship for one of the variables to that model, and is the closest to the underlying data generating mechanism.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model_interact</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span>
  <span class='va'>model_baseline</span>,
  <span class='va'>.</span> <span class='op'>~</span> <span class='va'>.</span> <span class='op'>+</span> <span class='va'>b1</span><span class='op'>:</span><span class='va'>b2</span> <span class='op'>+</span> <span class='va'>b2</span><span class='op'>:</span><span class='va'>x1</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  seed  <span class='op'>=</span> <span class='fl'>1234</span>
<span class='op'>)</span>

<span class='va'>model_interact_nonlin</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span>
  <span class='va'>model_interact</span>,
  <span class='va'>.</span> <span class='op'>~</span> <span class='va'>.</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/s.html'>s</a></span><span class='op'>(</span><span class='va'>x3</span><span class='op'>)</span>,
  cores <span class='op'>=</span> <span class='fl'>4</span>,
  seed  <span class='op'>=</span> <span class='fl'>1234</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="basic-prediction">Basic prediction</h2>
<p>With models in hand, let’s look at our basic predictive capabilities. We can get fitted values which include ‘confidence’ intervals, or predictions, which include ‘prediction’ intervals that include the uncertainty for a new observation. We can specify these as follows. First we create a small data set to make some predictions on. It will include both values for of the binary covariates, and the means of the numeric covariates (0).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>prediction_data</span> <span class='op'>=</span> <span class='fu'>crossing</span><span class='op'>(</span>
  b1 <span class='op'>=</span> <span class='fl'>0</span><span class='op'>:</span><span class='fl'>1</span>,
  b2 <span class='op'>=</span> <span class='fl'>0</span><span class='op'>:</span><span class='fl'>1</span>,
  x1 <span class='op'>=</span> <span class='fl'>0</span>,
  x2 <span class='op'>=</span> <span class='fl'>0</span>,
  x3 <span class='op'>=</span> <span class='fl'>0</span>
<span class='op'>)</span>

<span class='co'># fitted values</span>
<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/fitted.values.html'>fitted</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span><span class='op'>)</span>  
</code></pre>
</div>
<pre><code>     Estimate Est.Error     Q2.5    Q97.5
[1,] 3.510943 0.3515038 2.817057 4.201287
[2,] 3.784720 0.3517490 3.070184 4.497029
[3,] 3.854369 0.3461804 3.164223 4.550382
[4,] 4.351891 0.3518805 3.651440 5.097923
[5,] 3.171170 0.3473440 2.513093 3.888691
[6,] 3.900029 0.3440698 3.233128 4.602300</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># new predictions</span>
<span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>
  <span class='va'>prediction_data</span>,
  <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, newdata <span class='op'>=</span> <span class='va'>prediction_data</span>, re_formula <span class='op'>=</span> <span class='cn'>NA</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
<pre><code>  b1 b2 x1 x2 x3 Estimate Est.Error      Q2.5    Q97.5
1  0  0  0  0  0 2.702195  1.062798 0.6371021 4.726339
2  0  1  0  0  0 2.549677  1.015919 0.5020679 4.586656
3  1  0  0  0  0 3.472134  1.060215 1.4655644 5.618881
4  1  1  0  0  0 3.338356  1.011263 1.3089615 5.320062</code></pre>
</div>
<p>In general, we’d always like to visualize the predictions. We can do so as we did before with the <span class="func" style="">conditional_effects</span> function, which would also allow us to set specific covariate values. For the third plot of the nonlinear effect below, I modify the basic conditional effects plot that <span class="pack" style="">brms</span> provides for a slightly cleaner visualization.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/conditional_effects.brmsfit.html'>conditional_effects</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, effects <span class='op'>=</span> <span class='st'>'x2'</span>, conditions <span class='op'>=</span> <span class='va'>prediction_data</span><span class='op'>[</span><span class='fl'>1</span>,<span class='op'>]</span><span class='op'>)</span>
</code></pre>
</div>
<img src="practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-1.svg" width="624" style="display: block; margin: auto;" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/conditional_effects.brmsfit.html'>conditional_effects</a></span><span class='op'>(</span><span class='va'>model_interact</span>, effects <span class='op'>=</span> <span class='st'>'x1:b2'</span><span class='op'>)</span>
</code></pre>
</div>
<img src="practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-2.svg" width="624" style="display: block; margin: auto;" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>init</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/conditional_effects.brmsfit.html'>conditional_effects</a></span><span class='op'>(</span><span class='va'>model_interact_nonlin</span>, effects <span class='op'>=</span> <span class='st'>'x3'</span>, spaghetti <span class='op'>=</span> <span class='cn'>T</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="practical-bayes-part-ii_files/figure-html5/conditional-effects-model-comparison-show-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<p>Expanding your story through prediction is essential to helping your audience understand the model on a practical level. You would do well to spend time looking at specific data scenarios, especially in the case of nonlinear models (e.g. GLM) and models with interactions.</p>
<h2 id="model-comparison">Model Comparison</h2>
<p>In typical situations it is good to have competing models, and having additional models allows us to see if improvements can be made in one way or another, both to our models, and potentially to our way of thinking about them. In a general sense, we will go about things very similarly in the Bayesian context that we would elsewhere. However, we’ll also more easily apply other approaches that are not so commonly used (even if they can be).</p>
<h3 id="choosing-a-model">Choosing a model</h3>
<p>In traditional contexts, we can use a specific approach to pit competing models against one another, selecting the ‘best’ model based on a particular metric, for example, AIC, cross-validation error, etc. With ‘error metrics’, the model with the lowest value is the winner. In this case, nothing is new in the Bayesian world. Here, we can use estimates like <em>WAIC</em> and <em>LOOIC</em> for model comparison, much like you would <em>AIC</em> to compare models in traditional frameworks. The values themselves don’t tell us much, but in comparing models, lower means less predictive error for these ‘information criteria’ metrics, which is what we want<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, and since we’re Bayesian, we will even have estimates of uncertainty for these values as well. We also have cross-validation approaches (which IC metrics approximate), which we will demonstrate later.</p>
<p>With our new models added to the mix, we can now make some comparisons using <span class="func" style="">loo_compare</span>. First, we’ll add LOOIC estimates to our models, which are not estimated by default.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model_baseline</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/add_criterion.html'>add_criterion</a></span><span class='op'>(</span><span class='va'>model_baseline</span>,  <span class='st'>'loo'</span><span class='op'>)</span>
<span class='va'>model_interact</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/add_criterion.html'>add_criterion</a></span><span class='op'>(</span><span class='va'>model_interact</span>, <span class='st'>'loo'</span><span class='op'>)</span>
<span class='va'>model_interact_nonlin</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/add_criterion.html'>add_criterion</a></span><span class='op'>(</span><span class='va'>model_interact_nonlin</span>, <span class='st'>'loo'</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>To start, we’ll show the LOOIC result for the baseline model. We have the total expected log probability (<code>elpd_loo</code>) for the leave-one-out observations. We also get stuff like <code>p_loo</code>, which is the effective number of parameters. For those familiar with penalized maximum likelihood, these are familiar analogues. However we also get a summary regarding <code>Pareto k values</code>, which we’ll talk about soon.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># example</span>
<span class='fu'><a href='https://rdrr.io/pkg/brms/man/loo.brmsfit.html'>loo</a></span><span class='op'>(</span><span class='va'>model_baseline</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Computed from 1000 by 1000 log-likelihood matrix

         Estimate   SE
elpd_loo  -1500.3 22.0
p_loo        88.1  3.8
looic      3000.7 44.0
------
Monte Carlo SE of elpd_loo is 0.4.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     993   99.3%   298       
 (0.5, 0.7]   (ok)         7    0.7%   186       
   (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      

All Pareto k estimates are ok (k &lt; 0.7).
See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
</div>
<p>Let’s now compare the baseline model to the others models using <span class="func" style="">loo_compare</span>. It shows the ‘best’ (lowest-valued) model first, followed by the others. We get the difference of each elpd vs. the lowest, also get a standard error for this difference, which you could use to help assess how different the values are statistically. Just by this standard, the model that is based on the underlying data generating mechanism is the clear winner, as we would expect.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/loo_compare.brmsfit.html'>loo_compare</a></span><span class='op'>(</span>
  <span class='va'>model_baseline</span>, 
  <span class='va'>model_interact</span>,
  <span class='va'>model_interact_nonlin</span>
<span class='op'>)</span>
</code></pre>
</div>
<pre><code>                      elpd_diff se_diff
model_interact_nonlin   0.0       0.0  
model_interact        -44.4       9.3  
model_baseline        -45.7       9.6  </code></pre>
</div>
<p>Now let’s compare several metrics available to us. In this particular setting, all are generally in agreement in the rank order of the models, though there appears to be no meaningful difference between the baseline and interaction models.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
R2
</th>
<th style="text-align:right;">
loo_R2
</th>
<th style="text-align:right;">
WAIC
</th>
<th style="text-align:right;">
LOOIC
</th>
<th style="text-align:right;">
ELPD
</th>
<th style="text-align:right;">
weight
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
baseline
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
2998.65
</td>
<td style="text-align:right;">
3000.65
</td>
<td style="text-align:right;">
-1500.33
</td>
<td style="text-align:right;">
1.496607e-05
</td>
</tr>
<tr>
<td style="text-align:left;">
interact
</td>
<td style="text-align:right;">
0.49
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
2995.76
</td>
<td style="text-align:right;">
2998.06
</td>
<td style="text-align:right;">
-1499.03
</td>
<td style="text-align:right;">
3.436191e-07
</td>
</tr>
<tr>
<td style="text-align:left;">
interact_nonlin
</td>
<td style="text-align:right;">
0.53
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
2906.68
</td>
<td style="text-align:right;">
2909.16
</td>
<td style="text-align:right;">
-1454.58
</td>
<td style="text-align:right;">
9.999847e-01
</td>
</tr>
</tbody>
</table>
</div>
<p>For our ultimate model comparison we want to stick to using the IC values. As far as choosing between WAIC vs. LOOIC, the latter has better diagnostics for noting whether there are potential problems in using it. In practice, they will almost always agree with one another. As we noted previously, LOOIC reflects the ELPD, and this value is used in constructing the model weights shown in the last column<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. The model weights can then be used in making final predictions (i.e. <a href="#model-averaging-1">model averaging</a>), or just providing a different way for your audience to gauge which model might be preferred.</p>
<h3 id="problems-at-the-loo">Problems at the loo</h3>
<p>After the model issues discussed in <a href="https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-i/">Part I</a>, the next most common point of confusion I see people have is with model comparison, and using LOO in particular. Part of the reason is that this is an area of ongoing research and development, and most of the tools and documentation are notably technical. Another reason is that these are not perfect tools. They can fail to show notable problems for models that are definitely misspecified, and flag models that are essentially okay. Sometimes they flag models that other indicators may suggest are better models relatively speaking, which actually isn’t a contradiction, but which may indicate an overfit situation.</p>
<p>So in general, no tool is perfect, but in the real world we have to get things, so let’s address a couple issues.</p>
<h5 id="not-so-different-models">Not so different models</h5>
<p>Let’s start with the case where models do not appear to perform very differently. If two models aren’t very different from one another, the usual response is to go with the simpler model. For example, if we were only comparing the baseline model vs. the interaction model, there really isn’t much difference in terms of LOOIC/ELPD. However, we will have to consider things a little differently in the Bayesian context. Consider the following two thoughts.</p>
<blockquote>
<p>The general issue is that with <em>unregularized</em> estimation such as least squares or maximum likelihood, adding parameters to a model (or making a model more complex) leads to overfitting. With regularized estimation such as multilevel modeling, Bayesian inference, lasso, deep learning, etc., the regularization adds complexity but in a way that reduces the problem of overfitting. So traditional notions of model complexity and tradeoffs are overturned. ~ Andrew Gelman</p>
</blockquote>
<blockquote>
<p>Sometimes a simple model will outperform a more complex model… Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well. ~ Radford Neal</p>
</blockquote>
<p>The take-home message here is that <em>simpler is not always better</em>. And to be frank, using <em>penalized</em> (a.k.a. <em>regularized</em>) approaches (e.g. lasso, ridge, mixed models) should probably be our default model in the non-Bayesian context, and it turns out that such approaches actually approximate a Bayesian one with specific priors. In the end, you may have to think about things a little more carefully, and given that you are using methods that can help avoid overfitting, you may instead lean on a more complex model with otherwise similar performing models. And that would be closer to how nature works anyway, which is always more complex than our brains can easily understand.</p>
<!-- ###### Loo warnings -->
<!-- So what should we do here? As an example, let's start with our complex model and get the leave-one-out criterion measure.  I will avoid as much technical jargon as possible so that the applied modeler can get on with things.  The first part are the stats that are used in the previous model comparison and weighting, particularly the elpd_loo[^looic].  We also get  influence statistics for our observed data.   -->
<!-- ```{r loo-basic} -->
<!-- loo(model_baseline) -->
<!-- loo(model_interact_nonlin) -->
<!-- ``` -->
<!-- ```{r pareto-compare, echo=FALSE} -->
<!-- pareto_probs = loo(model_interact_nonlin) -->
<!-- # str(pareto_probs) -->
<!-- loo_pit_interact_nonlin = pp_check(model_interact_nonlin, type = 'loo_pit') -->
<!-- loo_pit_baseline = pp_check(model_baseline, type = 'loo_pit') -->
<!-- # bind_rows( -->
<!-- #   loo_pit_baseline %>% layer_data(), -->
<!-- #   loo_pit_interact_nonlin %>% layer_data(), -->
<!-- #   .id = 'model' -->
<!-- # ) %>%  -->
<!-- #   mutate( -->
<!-- #     model = factor(model, labels = c('baseline', 'complex')), -->
<!-- #     alpha = rep(c(1, .5), e = 1000) -->
<!-- #     ) %>%  -->
<!-- #   rename(Uniform = x, `LOO-PIT` = y) %>%  -->
<!-- #   ggplot(aes(Uniform, `LOO-PIT`)) + -->
<!-- #   geom_line(aes(color = model, alpha = I(alpha)), size = 2) + -->
<!-- #   geom_line(aes(y = theoretical), color = '#990021', alpha = .5) + -->
<!-- #   scico::scale_color_scico_d(begin = .25, end = .75) + -->
<!-- #   theme_clean() -->
<!-- # main_df %>%  -->
<!-- #   slice(which(pareto_probs$diagnostics$pareto_k > .5)) %>%  -->
<!-- #   bind_cols(pareto_probs$diagnostics %>% -->
<!-- #               as_tibble() %>% -->
<!-- #               slice(which(pareto_probs$diagnostics$pareto_k > .5))) %>%  -->
<!-- #   bind_cols(pareto_probs$pointwise %>% -->
<!-- #               as_tibble() %>% -->
<!-- #               slice(which(pareto_probs$diagnostics$pareto_k > .5))) -->
<!-- ``` -->
<h5 id="pareto-values">Pareto values</h5>
<p>Let’s look again at the basic result from using the <span class="func" style="">loo</span> function.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/loo.brmsfit.html'>loo</a></span><span class='op'>(</span><span class='va'>model_interact</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Computed from 1000 by 1000 log-likelihood matrix

         Estimate   SE
elpd_loo  -1499.0 22.0
p_loo        89.9  4.0
looic      2998.1 44.0
------
Monte Carlo SE of elpd_loo is 0.4.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     995   99.5%   161       
 (0.5, 0.7]   (ok)         5    0.5%   376       
   (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      

All Pareto k estimates are ok (k &lt; 0.7).
See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
</div>
<p>We haven’t yet discussed <em>Pareto values</em>, but it is not uncommon to get a result with some values that are not ‘good’ or ‘ok’. If you happen to see Pareto values in the ‘bad’ or ‘very bad’ group, what does it mean? You can read the definition provided <a href="https://mc-stan.org/loo/reference/loo-glossary.html#pareto-k-estimates">here</a>, but it may not help many due to the background knowledge needed to parse it. However, you can just understand it as an (leave-one-out) <em>extreme value</em> diagnostic, and if it is a problem, it mostly means your LOOIC may not be good for comparing models.</p>
<p>As in the standard model setting, ‘outliers’ indicate <em>model incompetence</em>, or in other words, the model is unable to understand such observations. Unless you have reason to suspect something inherently wrong in the data (e.g. an incorrect value/typo), an outlier is a sign that your model is not able to capture the data fully. It definitely is <em>not</em> a reason to remove the observation!</p>
<p>If you have Pareto values &gt; .7, you may recalculate LOOIC with the options provided by the <span class="func" style="">loo</span> function or use the <span class="func" style="">reloo</span> function, getting a better estimate that could then be used in, for example, <a href="#model-averaging-1">model stacking</a> for prediction. If you don’t discover many outliers, it probably won’t make much difference in your final estimates and conclusions, and so probably isn’t worth the trouble pursing much further. The output for Pareto values doesn’t even save the row identifying information that would make it easy to find which observations are the problem, but you can do something like the following if you need to.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>pareto</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/loo.brmsfit.html'>loo</a></span><span class='op'>(</span><span class='va'>model_interact_nonlin</span><span class='op'>)</span>

<span class='va'>problems</span> <span class='op'>=</span> <span class='va'>pareto</span><span class='op'>$</span><span class='va'>pointwise</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>rowid_to_column</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='va'>influence_pareto_k</span> <span class='op'>&gt;</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>pull</span><span class='op'>(</span><span class='va'>rowid</span><span class='op'>)</span>

<span class='va'>model_interact_nonlin</span><span class='op'>$</span><span class='va'>data</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>mutate</span><span class='op'>(</span>rank <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rank.html'>rank</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>slice</span><span class='op'>(</span><span class='va'>problems</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>           y b1 b2         x1         x2          x3 group rank
1  4.8358455  0  0  1.6595205 -0.1663858  0.03627905     6  902
2  3.9232800  0  1  0.2235292  0.0699854  0.46457410    37  748
3  6.7825956  0  1  1.0725661 -0.6440937  1.72027097    37  999
4  2.3935576  0  1 -0.6799355  0.2057128 -1.12517628    45  366
5  3.0636922  1  1  0.5484042 -0.8082104 -0.48645929    64  544
6  8.1985399  1  1  0.3636720  0.0652158  1.37603123    68 1000
7  2.1391887  0  1 -0.8143745  0.5552497  2.07192410    69  301
8  0.1456969  1  1 -1.0297148 -0.8834361 -1.24675264    84   31
9 -1.1238591  1  0  0.8573758  0.6268734 -0.33549539    97    3</code></pre>
</div>
<p>As we might have expected, the observations with the more extreme target values are likely to be problems (rank closer to 1 or 1000), but for some of these, there is nothing to suggest why they might be difficult, and it’s even harder to speculate in typical modeling situations with more predictors and complexity. Furthermore, outside of additional model complexity, which might then hamper interpretation, there is often little we can do about this, or at least, what we can do is generally not obvious in applied settings.</p>
<h2 id="model-averaging">Model Averaging</h2>
<p>With the previous statistics for model comparison we can obtain relative model weights, using the <span class="func" style="">model_weights</span> function. This essentially spreads the total probability of the models across all those being compared. These weights in turn allow us to obtain (weighted) average predictions. The key idea being that we do not select a ‘best’ model, but rather combine their results for predictive purposes<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>We can start by comparing the first two models. Adding the interactions helped, and comparing the weights suggests that the interaction model would be contributing most to the averaged predictions.</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code>Method: stacking
------
               weight
model_baseline 0.288 
model_interact 0.712 </code></pre>
</div>
<p>If we compare the baseline to our most complex model, almost the entirety of the weight is placed on the latter.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/pkg/brms/man/loo_model_weights.brmsfit.html'>loo_model_weights</a></span><span class='op'>(</span><span class='va'>model_baseline</span>, <span class='va'>model_interact_nonlin</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Method: stacking
------
                      weight
model_baseline        0.000 
model_interact_nonlin 1.000 </code></pre>
</div>
<p>Now we compare all three, with roughly the same conclusion.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
model_baseline
</th>
<th style="text-align:right;">
model_interact
</th>
<th style="text-align:right;">
model_interact_nonlin
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1e-05
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.99998
</td>
</tr>
</tbody>
</table>
</div>
<p>Now what about those average predictions? Let’s create a data frame that sets the continuous covariates at their means, and at each level of the categorical covariates. For our purposes here, we will also ignore group effects<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. We then will make average predictions for those observations using <span class="func" style="">pp_average</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>prediction_data</span> <span class='op'>=</span> <span class='fu'>crossing</span><span class='op'>(</span>
  b1 <span class='op'>=</span> <span class='fl'>0</span><span class='op'>:</span><span class='fl'>1</span>,
  b2 <span class='op'>=</span> <span class='fl'>0</span><span class='op'>:</span><span class='fl'>1</span>,
  x1 <span class='op'>=</span> <span class='fl'>0</span>,
  x2 <span class='op'>=</span> <span class='fl'>0</span>,
  x3 <span class='op'>=</span> <span class='fl'>0</span>
<span class='op'>)</span>

<span class='va'>average_predictions</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/pp_average.brmsfit.html'>pp_average</a></span><span class='op'>(</span>
  <span class='va'>model_baseline</span>,
  <span class='va'>model_interact</span>,
  <span class='va'>model_interact_nonlin</span>,
  newdata <span class='op'>=</span> <span class='va'>prediction_data</span>,
  re_formula <span class='op'>=</span> <span class='cn'>NA</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
b1
</th>
<th style="text-align:right;">
b2
</th>
<th style="text-align:right;">
x1
</th>
<th style="text-align:right;">
x2
</th>
<th style="text-align:right;">
x3
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Est.Error
</th>
<th style="text-align:right;">
Q2.5
</th>
<th style="text-align:right;">
Q97.5
</th>
<th style="text-align:right;">
Baseline Estimate
</th>
<th style="text-align:right;">
Model Nonlin Est.
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.71
</td>
<td style="text-align:right;">
1.03
</td>
<td style="text-align:right;">
0.66
</td>
<td style="text-align:right;">
4.60
</td>
<td style="text-align:right;">
2.69
</td>
<td style="text-align:right;">
2.74
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.32
</td>
<td style="text-align:right;">
0.96
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
4.28
</td>
<td style="text-align:right;">
2.55
</td>
<td style="text-align:right;">
2.30
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
1.03
</td>
<td style="text-align:right;">
1.09
</td>
<td style="text-align:right;">
4.97
</td>
<td style="text-align:right;">
3.49
</td>
<td style="text-align:right;">
2.95
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3.07
</td>
<td style="text-align:right;">
1.03
</td>
<td style="text-align:right;">
1.05
</td>
<td style="text-align:right;">
5.05
</td>
<td style="text-align:right;">
3.35
</td>
<td style="text-align:right;">
3.08
</td>
</tr>
</tbody>
</table>
</div>
<p>As expected, we can see that the averaged predictions are essentially the same as what we would get from the model with all the weight. In other scenarios, you may be dealing with a more nuanced result.</p>
<h2 id="cross-validation">Cross-Validation</h2>
<p>In machine learning contexts, cross-validation is the default approach to considerations of model performance. We can do so easily within the Bayesian context as well. I go ahead and do so for a single model, as well as all three models, so we can see how our previous performance metrics might change. In general, prediction on a validation set will be expected to be worse than on the training data<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, but it is the better estimate of prediction error.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/HenrikBengtsson/future'>future</a></span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/pkg/future/man/plan.html'>plan</a></span><span class='op'>(</span><span class='va'>multisession</span><span class='op'>)</span>

<span class='va'>model_interact_nonlin_cv</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/kfold.brmsfit.html'>kfold</a></span><span class='op'>(</span>
  <span class='va'>model_interact_nonlin</span>,
  K <span class='op'>=</span> <span class='fl'>5</span>,
  chains <span class='op'>=</span> <span class='fl'>1</span>,
  save_fits <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>

<span class='va'>model_all_cv</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/kfold.brmsfit.html'>kfold</a></span><span class='op'>(</span>
  <span class='va'>model_baseline</span>,
  <span class='va'>model_interact</span>,
  <span class='va'>model_interact_nonlin</span>,
  K <span class='op'>=</span> <span class='fl'>5</span>,
  chains <span class='op'>=</span> <span class='fl'>1</span>,
  save_fits <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/pkg/future/man/plan.html'>plan</a></span><span class='op'>(</span><span class='va'>sequential</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>With a single cross-validation model in place, we can then make predictions with it to get the test error or other metrics of interest. As we expect, the training error, i.e. that on the original/full data is better than the test error, but the latter is the better estimate of our model error, and thus a better metric for comparing models.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>test_predictions</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/brms/man/kfold_predict.html'>kfold_predict</a></span><span class='op'>(</span><span class='va'>model_interact_nonlin_cv</span><span class='op'>)</span>


<span class='va'>train_error</span> <span class='op'>=</span> <span class='fu'>yardstick</span><span class='fu'>::</span><span class='fu'><a href='https://yardstick.tidymodels.org/reference/rmse.html'>rmse_vec</a></span><span class='op'>(</span>truth    <span class='op'>=</span> <span class='va'>model_interact_nonlin</span><span class='op'>$</span><span class='va'>data</span><span class='op'>$</span><span class='va'>y</span>,
                                  estimate <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/fitted.values.html'>fitted</a></span><span class='op'>(</span><span class='va'>model_interact_nonlin</span><span class='op'>)</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span><span class='op'>)</span>

<span class='va'>test_error</span>  <span class='op'>=</span> <span class='fu'>yardstick</span><span class='fu'>::</span><span class='fu'><a href='https://yardstick.tidymodels.org/reference/rmse.html'>rmse_vec</a></span><span class='op'>(</span>truth    <span class='op'>=</span> <span class='va'>test_predictions</span><span class='op'>$</span><span class='va'>y</span>,
                                  estimate <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/colSums.html'>colMeans</a></span><span class='op'>(</span><span class='va'>test_predictions</span><span class='op'>$</span><span class='va'>yrep</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
train_error
</th>
<th style="text-align:right;">
test_error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.934
</td>
<td style="text-align:right;">
1.036
</td>
</tr>
</tbody>
</table>
</div>
<p>Now let’s revisit our LOOIC comparison, only now it is based on LOOIC via the cross-validation process. We would come to the same conclusions, but we can see that the differences, while still substantial, are not as great. In addition, other standard metrics can help validate the Bayesian-specific metrics, as RMSE does here.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## model_all_cv$diffs</span>
</code></pre>
</div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
elpd_diff
</th>
<th style="text-align:right;">
se_diff
</th>
<th style="text-align:right;">
elpd_kfold
</th>
<th style="text-align:right;">
rmse
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
model_interact_nonlin
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
-1482.69
</td>
<td style="text-align:right;">
1.07
</td>
</tr>
<tr>
<td style="text-align:left;">
model_interact
</td>
<td style="text-align:right;">
-22.67
</td>
<td style="text-align:right;">
11.30
</td>
<td style="text-align:right;">
-1505.36
</td>
<td style="text-align:right;">
1.09
</td>
</tr>
<tr>
<td style="text-align:left;">
model_baseline
</td>
<td style="text-align:right;">
-28.48
</td>
<td style="text-align:right;">
11.71
</td>
<td style="text-align:right;">
-1511.17
</td>
<td style="text-align:right;">
1.09
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="variable-selection">Variable Selection</h3>
<p>If desired, we can use cross-validation to help with feature selection. We’ve already discussed why this really shouldn’t be a concern, namely because there rarely is a reason to throw out variables regardless of how minimally important they might be. Furthermore, interactions among variables are the norm, not the exception. So while a variable might not do well on its own, it can be extremely important in how it interacts with another feature.</p>
<p>In any case, one can use the <span class="pack" style="">projpred</span> package to get a sense of this, and also why it can be problematic. For starters, we cannot test our nonlinear model due to its complexity<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. But we can also see that we would not choose the true underlying model using this approach. In addition, for expediency I had to turn off the random effects, otherwise this would take more time than I wanted to spend for this demo (the group effect would have been the first selected). In short, be prepared for issues that might accompany the complexities in your model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://mc-stan.org/projpred/'>projpred</a></span><span class='op'>)</span>

<span class='va'>model_feature_select_cv</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span><span class='va'>model_interact</span>, <span class='va'>.</span><span class='op'>~</span><span class='va'>.</span> <span class='op'>-</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>group</span><span class='op'>)</span>, cores <span class='op'>=</span> <span class='fl'>4</span><span class='op'>)</span>
<span class='va'>ref_model</span> <span class='op'>=</span> <span class='fu'><a href='https://mc-stan.org/projpred/reference/get-refmodel.html'>get_refmodel</a></span><span class='op'>(</span><span class='va'>model_feature_select_cv</span><span class='op'>)</span>  <span class='co'># reference model structure</span>

<span class='fu'><a href='https://rdrr.io/r/base/options.html'>options</a></span><span class='op'>(</span>mc.cores <span class='op'>=</span> <span class='fu'>parallel</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/r/parallel/detectCores.html'>detectCores</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>var_select</span> <span class='op'>=</span> <span class='fu'><a href='https://mc-stan.org/projpred/reference/cv_varsel.html'>cv_varsel</a></span><span class='op'>(</span><span class='va'>ref_model</span><span class='op'>)</span>   <span class='co'># will take a long time</span>
</code></pre>
</div>
</div>
<p>With results in place we can summarize and visualize our results, similar to how we have done before.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
size
</th>
<th style="text-align:left;">
solution_terms
</th>
<th style="text-align:right;">
elpd
</th>
<th style="text-align:right;">
elpd.se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
-1779.673
</td>
<td style="text-align:right;">
21.586
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
b1
</td>
<td style="text-align:right;">
-1736.588
</td>
<td style="text-align:right;">
21.959
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
x3
</td>
<td style="text-align:right;">
-1714.826
</td>
<td style="text-align:right;">
21.397
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
b1:b2
</td>
<td style="text-align:right;">
-1715.755
</td>
<td style="text-align:right;">
21.552
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
b2:x1
</td>
<td style="text-align:right;">
-1715.668
</td>
<td style="text-align:right;">
21.700
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
x1
</td>
<td style="text-align:right;">
-1715.799
</td>
<td style="text-align:right;">
21.709
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
x2
</td>
<td style="text-align:right;">
-1716.550
</td>
<td style="text-align:right;">
21.714
</td>
</tr>
<tr>
<td style="text-align:left;">
9
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
b2
</td>
<td style="text-align:right;">
-1716.550
</td>
<td style="text-align:right;">
21.714
</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># plot predictive performance on training data</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>var_select</span>, stats <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'elpd'</span>, <span class='st'>'rmse'</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/cv-feature-selection-show-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://mc-stan.org/projpred/reference/solution_terms.html'>solution_terms</a></span><span class='op'>(</span><span class='va'>var_select</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] &quot;b1&quot;    &quot;x3&quot;    &quot;b1:b2&quot; &quot;b2:x1&quot; &quot;x1&quot;    &quot;x2&quot;    &quot;b2&quot;   </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>mcmc_areas</span><span class='op'>(</span>
  <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>ref_model</span><span class='op'>$</span><span class='va'>fit</span><span class='op'>)</span>,
  pars <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'b_b11'</span>, <span class='st'>'b_x3'</span>, <span class='st'>'b_x1'</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>coord_cartesian</span><span class='op'>(</span>xlim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>2</span>, <span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="practical-bayes-part-ii_files/figure-html5/cv-feature-select-mcmc-area-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<h2 id="the-rabbit-hole-of-model-comparsion">The rabbit hole of model comparsion</h2>
<p>If you start to look more into this, there are numerous technical articles, whole websites, and various discussions regarding how to go about it. I’m guessing many do not want to try and parse highly technical information, only to still feel confused about what to actually do. Many suggestions amount to ‘your model is probably misspecified’, but without additional thoughts on how to proceed. Some of the data issues that lead to problems are just the reality of data doing what data does. There are also suggestions that posterior predictive checks (PPCs) can be used to detect the problem. But a difficulty here is that these don’t detect anything by themselves without very specific directed action, nor do they typically have a standard metric to report, so the practical utility does have its limits. In addition, it’s not clear to me that issues or problems regarding specific statistics for model comparison (e.g. LOOIC estimation) should be a basis for altering a model, unless there is an obvious path for doing so. And let’s face it, if there was, you’d probably already be taking it.</p>
<p>For those that do want to go down the rabbit hole, I have numerous links in the <a href="#resources">resources section</a>.</p>
<h2 id="solutions-for-model-comparison">Solutions for Model Comparison</h2>
<p>When doing model comparison, the following summarizes some basic steps you can take.</p>
<ul>
<li><p>Don’t assume you’ll have any certainty about some model being ‘best’.</p></li>
<li><p>Use the metrics noted above, e.g. LOOIC, when making comparisons (not R<sup>2</sup>).</p></li>
<li><p>Avoid the problem and fit the model that includes everything of interest, assuming you have a decent data size to do so. It is likely you can still learn some things about the model by comparing it to others.</p></li>
<li><p>Variable selection is typically just a model comparison problem restated differently, and in a lot of cases I’ve come across, a misguided endeavor. If something is even minimally important, there is no reason to throw it out, as you’d just have worse predictions doing so. With complex models, you can’t assess one variable without consideration of others, so trying to say that one is more important than the others doesn’t really make sense.</p></li>
<li><p>If some application performance measure is obvious and available to assess, pick a model that does best in that setting.</p></li>
<li><p>If trying to select among many competing models, e.g. feature selection, you should consider why you are in this situation. If you don’t have much data, then the usual model selection criteria may lead you notably astray. If you have a lot of data, consider why you need to select a subset of predictors and not use all available. If you are somewhere in between, note that you’ll likely spend a lot more time here and still not be confident in the results. However, there are approaches, such as those in the <span class="pack" style="">projpred</span> package, that might be useful, but likely will only work for simpler models.</p></li>
</ul>
<h1 id="summary-the-practical-approach-to-bayesian-models">Summary: The Practical Approach to Bayesian Models</h1>
<p>For applied analysts, just a few steps can go a long way toward making you feel better about your model. You can assess your priors in a straightforward fashion before starting, and that will not only help you have more confidence in your results, but likely also help you convince others of the results as well. Once you run the model, explore it in-depth, and take advantage of taking the Bayesian approach that allows you to more easily explore it. Many tools are available for you to asses model effectiveness, use them!</p>
<p>Key to understanding any model is through prediction, which can make even complex settings more relatable. You can pit models against one another to see which performs best in a predictive sense, but note that more complexity is more realistic, and in the Bayesian world, you don’t have to choose a ‘best’ model.</p>
<p>You can use the diagnostics to further understand why and how the model isn’t perfect, which might give you some ideas on how you might do things differently in the future. However, the diagnostic criteria and other statistics may themselves have problems, the solutions of which are difficult. You should be okay with leaving some aspects of your model imperfect. There’s always next time!</p>
<p>All in all, any modeling endeavor done well, Bayesian or otherwise, will take time, and often encounter difficulties. With the right tools, working through these difficulties can lead to a better understanding of both the data (i.e. the world around us), and how we think about it!</p>
<h1 id="resources">Resources</h1>
<h3 id="prior-checks">Prior Checks</h3>
<ul>
<li><a href="https://statmodeling.stat.columbia.edu/2019/08/10/">Gelman’s prior check approach</a></li>
<li><a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan Group’s Prior Choice Recommendations</a></li>
</ul>
<h3 id="r2">R<sup>2</sup></h3>
<ul>
<li><p><a href="https://avehtari.github.io/bayes_R2/bayes_R2.html">Bayesian R2 and LOO-R2</a> Vehtari et al. </p></li>
<li><p>Andrew Gelman, Ben Goodrich, Jonah Gabry, and Aki Vehtari (2018). R-squared for Bayesian regression models. The American Statistician, <a href="doi:10.1080/00031305.2018.1549100" class="uri">doi:10.1080/00031305.2018.1549100</a>. <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/bayes_R2_v3.pdf">Online Preprint</a>.</p></li>
</ul>
<h3 id="model-comparison-1">Model Comparison</h3>
<ul>
<li><p><a href="https://mc-stan.org/loo/reference/loo-glossary.html">The LOO glossary</a></p></li>
<li><p><a href="https://mc-stan.org/loo/articles/loo2-weights.html">LOO model weights</a></p></li>
<li><p><a href="https://avehtari.github.io/modelselection/CV-FAQ.html#16_What_to_do_if_I_have_many_high_Pareto_(k)%E2%80%99s">16 What to do if I have many high Pareto k’s?</a></p></li>
</ul>
<h4 id="stan-forum-threads">Stan Forum Threads</h4>
<ul>
<li><p><a href="https://discourse.mc-stan.org/t/understanding-looic/13409/6">Understanding LOOIC</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/can-waic-looic-be-used-to-compare-models-with-different-likelihoods/7380">Can WAIC/LOOIC be used to compare models with different likelihoods?</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/a-quick-note-what-i-infer-from-p-loo-and-pareto-k-values/3446">A quick note what I infer from p_loo and Pareto km values</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/recommendations-for-what-to-do-when-k-exceeds-0-5-in-the-loo-package/3417">Recommendations for what to do when k exceeds 0.5 in the loo package?</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/improve-model-with-some-observations-pareto-0-7/17500">Improve model with some observations Pareto &gt;0.7</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/pareto-k-for-outlier-detection/12177/9">Pareto K for outlier detection 1</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/good-pp-check-and-r-square-but-large-pareto-k-values/17678">Possibly incompatible metrics</a></p></li>
</ul>
<h3 id="pareto-values-1">Pareto values</h3>
<ul>
<li><p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2019). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646/">preprint arXiv:1507.02646</a></p></li>
<li><p><a href="https://discourse.mc-stan.org/t/a-quick-note-what-i-infer-from-p-loo-and-pareto-k-values/3446">Aki Vehtari’s A quick note what I infer from p_loo and Pareto k values</a></p></li>
<li><p><a href="https://avehtari.github.io/modelselection/CV-FAQ.html#16_What_to_do_if_I_have_many_high_Pareto_(k)%E2%80%99s">What to do if I have many high Pareto k?</a></p></li>
</ul>
<h3 id="model-averaging-1">Model Averaging</h3>
<ul>
<li><p>Vehtari, A., Gelman, A., and Gabry, J. (2017a). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing. 27(5), 1413–1432. <a href="doi:10.1007/s11222-016-9696-4" class="uri">doi:10.1007/s11222-016-9696-4</a> (<a href="http://link.springer.com/article/10.1007%2Fs11222-016-9696-4">journal version</a>, <a href="https://arxiv.org/abs/1507.04544">preprint arXiv:1507.04544</a>).</p></li>
<li><p>Yao, Y., Vehtari, A., Simpson, D., and Gelman, A. (2018) Using stacking to average Bayesian predictive distributions. Bayesian Analysis, advance publication, <a href="doi:10.1214/17-BA1091" class="uri">doi:10.1214/17-BA1091</a>. (<a href="https://projecteuclid.org/euclid.ba/1516093227">online</a>).</p></li>
</ul>
<h3 id="cross-validation-1">Cross-Validation</h3>
<ul>
<li><p><a href="https://avehtari.github.io/modelselection/CV-FAQ.html">CV FAQ</a></p></li>
<li><p><a href="https://mc-stan.org/projpred/articles/quickstart.html">Projpred Quickstart</a></p></li>
<li><p><a href="https://rawgit.com/avehtari/modelselection_tutorial/master/roaches.html#22_cross-validation_checking">Bayesian data analysis - roaches cross-validation demo</a></p></li>
</ul>
<h3 id="misc">Misc</h3>
<ul>
<li><p><a href="https://mc-stan.org/docs/2_26/stan-users-guide/problematic-posteriors-chapter.html">Problematic Posteriors</a></p></li>
<li><p>Gabry, J. , Simpson, D. , Vehtari, A. , Betancourt, M. and Gelman, A. (2019), Visualization in Bayesian workflow. J. R. Stat. Soc. A, 182: 389-402. <a href="doi:10.1111/rssa.12378" class="uri">doi:10.1111/rssa.12378</a>. (<a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12378">journal version</a>, <a href="https://arxiv.org/abs/1709.01449">arXiv preprint</a>, <a href="https://github.com/jgabry/bayes-vis-paper">code on GitHub</a>)</p></li>
<li><p><a href="http://mc-stan.org/cmdstanr/articles/cmdstanr.html">Use CmdStan to save memory</a></p></li>
<li><p><a href="https://jrnold.github.io/bayesian_notes/">Jeffrey Arnold’s Bayesian Notes</a> has nice examples of many models and good summaries otherwise</p></li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>If you were coding in Stan directly, you can run a single iteration to see if your code compiles at all.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Daniel Lakeland proposes (<a href="https://statmodeling.stat.columbia.edu/2019/08/10/">as a comment in the discussion of the 10% approach outlined</a>) an alternative approach is whether the posterior estimate falls within the 95% highest density interval of the prior. This is available via the method argument in the demonstrated function (<code>method = 'lakeland'</code>).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>As in the text of the output, this is the same as testing whether abs(b1) + abs(b2) - 2*x1 &gt; 0. In this case the resulting value is greater than zero with high probability.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Similar to AIC, LOOIC is ~ -2*expected log posterior density (<em>ELPD</em>), similar to how we use -2*log likelihood (a.k.a. deviance) in standard approaches for AIC. We don’t add a penalty for parameters here, and I think this is because the regularization is already built in to the modeling process, and the number of parameters might be more difficult to define in the Bayesian context with priors.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Technically we can use WAIC to produce weights like we do with AIC, e.g. <code>exp(waic) / sum(exp(all_waics))</code>, but this isn’t recommended. The stacking approach allows similar models to share their weight, while more unique models will mostly keep their weight as additional models are added.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Some might be familiar with Bayesian model averaging. Conceptually we aren’t changing much, but BMA assumes that one of our models is the true model, while the stacking approach underlying these weights does not. It is also different from conventional stacking in machine learning in that we are trying to average posterior predictive distributions, rather than point estimates.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>In other words, for prediction we set <code>re_formula = NA</code>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>At the time of this writing, the underlying use of the <span class="pack" style="">furrr</span> package defaults to not using a seed in it’s parallelization process, and then warns you that a seed has not been set for each repeated use of a cluster. Passing a seed through the seed argument won’t actually do anything presently here, so one will hope that <span class="pack" style="">furrr</span> will change their default behavior. It’s a nuisance that can be ignored though.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Perhaps this might be possible in a future release, but there are other complications that might make it problematic still.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Practical%20Bayes%20Part%20II&amp;url=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2021-02-28-practical-bayes-part-ii%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2021-02-28-practical-bayes-part-ii%2F&amp;title=Practical%20Bayes%20Part%20II">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://www.facebook.com/sharer/sharer.php?s=100&amp;p[url]=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2021-02-28-practical-bayes-part-ii%2F">
        <i class="fab fa-facebook"></i>
      </a>
    </span>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="updates-and-corrections">Corrections</h3>
  <p>If you see mistakes or want to suggest changes, please <a href="https://github.com//m-clark/m-clark.github.io/issues/new">create an issue</a> on the source repository.</p>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>. Source code is available at <a href="https://github.com//m-clark/m-clark.github.io">https://github.com//m-clark/m-clark.github.io</a>, unless otherwise noted. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Clark (2021, Feb. 28). Michael Clark: Practical Bayes Part II. Retrieved from https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{clark2021practical,
  author = {Clark, Michael},
  title = {Michael Clark: Practical Bayes Part II},
  url = {https://m-clark.github.io/posts/2021-02-28-practical-bayes-part-ii/},
  year = {2021}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<div class="distill-site-nav distill-site-footer">
  <div>


Michael Clark • 2021 •  <a href="https://m-clark.github.io">https://m-clark.github.io/</a>
</div>
</div>
<!--/radix_placeholder_navigation_after_body-->


</body>

</html>
