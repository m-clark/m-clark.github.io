---
title: "Convergence Problems"
description: |
  Lack of convergence got ya down? A plan of attack.
date: 2020-03-16
image: ../../img/convergence/warning.png
draft: false
bibliography: ../../bibs/conv_references.bib
nocite:  | 
  @bates2015parsimonious, @stackoverflow2014, @bolker2014, @lme4convergence2020
keywords: [mixed models, convergence, generalized linear mixed models, random effects, lme4, glmmTMB, lmer, glmer, regression, glm]
categories:
  - regression
  - mixed models
---

```{r setup, include=FALSE}
kable_df = function(..., digits = 3) {
  kable(..., digits = digits) %>%
    kable_styling(full_width = F)
}
```

> NB: This post was revisited when updating the website early 2025, and some changes were required. Attempts to keep things consistent were made, but if you feel you've found an issue, please post it at [GitHub](http://github.com/m-clark/m-clark.github.io/issues).


Prerequisite: Knowledge of regression modeling. Helpful would be to know something about mixed models and optimization.

Primary packages used:

```{r packages, cache=FALSE}

library(tidyverse)
library(tidyext)
library(broom)
library(kableExtra)
library(visibly)

library(lme4)
library(mixedup)  # http://m-clark.github.io/mixedup
```


## Intro

It is not uncommon that complex models lead to difficulties with convergence. Though the following example is a demo with the R package <span class="pack" style = "">lme4</span>, most of it would potentially apply to any complex modeling situation where convergence problems arise.  The goal is provide some steps one can take to get their models back on track.  The running example is taken from the data posted at this [stackoverflow question](https://stackoverflow.com/questions/23478792/warning-messages-when-trying-to-run-glmer-in-r). Ben Bolker's[^bolker] response there can be seen as the basis for this post, along with some extensions, updates and other organization.

## Data Setup

You can download the data from [here](https://github.com/m-clark/m-clark.github.io/raw/master/data/convergence.RDS) (RDS file), or go to the [stackoverflow discussion](https://stackoverflow.com/questions/23478792/warning-messages-when-trying-to-run-glmer-in-r) and paste the code there.  There isn't any real explanation of the variables unfortunately, though you can get a sense of some of them (e.g. Day, replicate, temperature, etc.).


```{r data-from-stack-overflow, echo=FALSE, eval=FALSE}
df = structure(list(SUR.ID = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 1L, 
1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 
3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 
1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 
3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 
1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 
3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 
1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 
3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 
1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 
3L, 1L, 1L, 2L, 2L), .Label = c("10185", "10186", "10250"), class = "factor"), 
    tm = structure(c(1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 
    1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 
    2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L
    ), .Label = c("CT", "PT-04"), class = "factor"), ValidDetections = c(0L, 
    0L, 6L, 5L, 1L, 7L, 0L, 0L, 5L, 8L, 7L, 3L, 0L, 0L, 1L, 4L, 
    1L, 0L, 0L, 0L, 0L, 1L, 2L, 1L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 
    0L, 3L, 5L, 5L, 4L, 0L, 0L, 6L, 7L, 6L, 5L, 0L, 0L, 0L, 1L, 
    2L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 23L, 
    21L, 15L, 28L, 11L, 27L, 22L, 31L, 29L, 30L, 32L, 45L, 18L, 
    19L, 29L, 26L, 32L, 43L, 7L, 5L, 7L, 4L, 6L, 10L, 0L, 0L, 
    0L, 0L, 0L, 0L, 24L, 22L, 19L, 23L, 21L, 34L, 9L, 13L, 30L, 
    25L, 33L, 21L, 4L, 18L, 22L, 29L, 11L, 38L, 2L, 7L, 5L, 7L, 
    6L, 9L, 0L, 0L, 0L, 0L, 0L, 0L, 23L, 20L, 24L, 26L, 29L, 
    34L, 6L, 7L, 5L, 4L, 6L, 10L, 0L, 0L, 3L, 0L, 1L, 6L, 0L, 
    0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 0L, 5L, 0L, 0L, 0L, 0L, 
    0L, 1L, 0L, 0L, 0L, 3L, 1L, 11L, 0L, 0L, 2L, 5L, 1L, 2L, 
    0L, 0L, 0L, 3L, 0L, 4L, 0L, 0L, 0L, 2L, 0L, 2L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 4L, 2L, 5L, 6L, 6L, 2L, 3L, 0L, 0L, 1L, 
    3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 21L, 12L, 
    15L, 8L, 23L, 7L, 2L, 2L, 1L, 1L), CountDetections = c(0L, 
    0L, 7L, 5L, 3L, 7L, 0L, 0L, 5L, 8L, 8L, 4L, 0L, 0L, 1L, 4L, 
    1L, 1L, 0L, 0L, 0L, 1L, 3L, 3L, 0L, 0L, 1L, 0L, 2L, 4L, 0L, 
    0L, 4L, 5L, 5L, 5L, 0L, 0L, 6L, 7L, 7L, 5L, 0L, 0L, 0L, 1L, 
    2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 2L, 23L, 
    21L, 18L, 28L, 11L, 27L, 23L, 31L, 29L, 30L, 34L, 45L, 19L, 
    19L, 29L, 26L, 32L, 43L, 7L, 5L, 7L, 4L, 6L, 10L, 0L, 0L, 
    0L, 0L, 0L, 0L, 24L, 22L, 19L, 23L, 21L, 34L, 10L, 15L, 30L, 
    25L, 34L, 24L, 4L, 19L, 23L, 29L, 13L, 38L, 2L, 7L, 5L, 7L, 
    7L, 9L, 0L, 0L, 0L, 0L, 0L, 0L, 23L, 20L, 24L, 26L, 29L, 
    34L, 6L, 7L, 5L, 4L, 6L, 10L, 0L, 0L, 4L, 1L, 1L, 7L, 0L, 
    0L, 0L, 3L, 2L, 1L, 0L, 0L, 0L, 3L, 0L, 5L, 0L, 0L, 2L, 2L, 
    0L, 1L, 0L, 0L, 0L, 5L, 1L, 11L, 0L, 0L, 3L, 5L, 1L, 2L, 
    0L, 0L, 2L, 3L, 0L, 6L, 0L, 0L, 0L, 3L, 0L, 3L, 0L, 0L, 1L, 
    0L, 0L, 1L, 0L, 0L, 6L, 2L, 5L, 6L, 7L, 4L, 5L, 1L, 0L, 3L, 
    3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 23L, 12L, 
    16L, 10L, 23L, 10L, 2L, 2L, 1L, 1L), FalseDetections = c(0L, 
    0L, 1L, 0L, 2L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 
    0L, 1L, 0L, 0L, 0L, 0L, 1L, 2L, 0L, 0L, 1L, 0L, 0L, 4L, 0L, 
    0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 
    0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 
    0L, 3L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 2L, 0L, 1L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 1L, 2L, 0L, 0L, 1L, 3L, 0L, 1L, 1L, 0L, 
    2L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 
    0L, 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 
    0L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 
    0L, 0L, 0L, 0L, 2L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 
    0L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 2L, 2L, 1L, 
    0L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 
    0L, 1L, 2L, 0L, 3L, 0L, 0L, 0L, 0L), replicate = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"), 
    Area = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L
    ), .Label = c("Drug Channel", "Finger"), class = "factor"), 
    Day = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L
    ), .Label = c("03/06/13", "2/22/13", "2/26/13", "2/27/13", 
    "3/14/13"), class = "factor"), R.det = c(0, 0, 0.857142857, 
    1, 0.333333333, 1, 0, 0, 1, 1, 0.875, 0.75, 0, 0, 1, 1, 1, 
    0, 0, 0, 0, 1, 0.666666667, 0.333333333, 0, 0, 0, 0, 1, 0, 
    0, 0, 0.75, 1, 1, 0.8, 0, 0, 1, 1, 0.857142857, 1, 0, 0, 
    0, 1, 1, 0.5, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.833333333, 
    1, 1, 1, 0.956521739, 1, 1, 1, 0.941176471, 1, 0.947368421, 
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 
    1, 1, 1, 1, 0.9, 0.866666667, 1, 1, 0.970588235, 0.875, 1, 
    0.947368421, 0.956521739, 1, 0.846153846, 1, 1, 1, 1, 1, 
    0.857142857, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 
    1, 1, 1, 1, 0, 0, 0.75, 0, 1, 0.857142857, 0, 0, 0, 0.333333333, 
    0.5, 1, 0, 0, 0, 0.666666667, 0, 1, 0, 0, 0, 0, 0, 1, 0, 
    0, 0, 0.6, 1, 1, 0, 0, 0.666666667, 1, 1, 1, 0, 0, 0, 1, 
    0, 0.666666667, 0, 0, 0, 0.666666667, 0, 0.666666667, 0, 
    0, 0, 0, 0, 0, 0, 0, 0.666666667, 1, 1, 1, 0.857142857, 0.5, 
    0.6, 0, 0, 0.333333333, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    0, 0.913043478, 1, 0.9375, 0.8, 1, 0.7, 1, 1, 1, 1), c.receiver.depth = c(-0.2, 
    -0.2, -0.2, -0.2, -0.2, -0.2, -0.22, -0.22, -0.22, -0.22, 
    -0.22, -0.22, -0.22, -0.22, -0.22, -0.22, -0.22, -0.22, -0.225, 
    -0.225, -0.225, -0.225, -0.225, -0.225, -0.225, -0.225, -0.225, 
    -0.225, -0.225, -0.225, -0.205, -0.205, -0.205, -0.205, -0.205, 
    -0.205, -0.185, -0.185, -0.185, -0.185, -0.185, -0.185, -0.18, 
    -0.18, -0.18, -0.18, -0.18, -0.18, -0.165, -0.165, -0.165, 
    -0.165, -0.165, -0.165, -0.14, -0.14, -0.14, -0.14, -0.14, 
    -0.14, -0.34, -0.34, -0.34, -0.34, -0.34, -0.34, -0.365, 
    -0.365, -0.365, -0.365, -0.365, -0.365, -0.365, -0.365, -0.365, 
    -0.365, -0.365, -0.365, -0.38, -0.38, -0.38, -0.38, -0.38, 
    -0.38, -0.385, -0.385, -0.385, -0.385, -0.385, -0.385, -0.395, 
    -0.395, -0.395, -0.395, -0.395, -0.395, -0.4, -0.4, -0.4, 
    -0.4, -0.4, -0.4, -0.395, -0.395, -0.395, -0.395, -0.395, 
    -0.395, -0.38, -0.38, -0.38, -0.38, -0.38, -0.38, -0.37, 
    -0.37, -0.37, -0.37, -0.37, -0.37, -0.285, -0.285, -0.285, 
    -0.285, -0.285, -0.285, -0.31, -0.31, -0.31, -0.31, -0.31, 
    -0.31, 0.22, 0.22, 0.22, 0.22, 0.22, 0.22, 0.225, 0.225, 
    0.225, 0.225, 0.225, 0.225, 0.225, 0.225, 0.225, 0.225, 0.225, 
    0.225, 0.21, 0.21, 0.21, 0.21, 0.21, 0.21, 0.185, 0.185, 
    0.185, 0.185, 0.185, 0.185, 0.175, 0.175, 0.175, 0.175, 0.175, 
    0.175, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.13, 0.13, 0.13, 
    0.13, 0.13, 0.13, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 
    0.215, 0.215, 0.215, 0.215, 0.215, 0.215, 0.54, 0.54, 0.54, 
    0.54, 0.54, 0.54, 0.525, 0.525, 0.525, 0.525, 0.525, 0.525, 
    0.515, 0.515, 0.515, 0.515, 0.515, 0.515, 0.545, 0.545, 0.545, 
    0.545, 0.545, 0.545, 0.525, 0.525, 0.525, 0.525), c.tm.depth = c(0.042807692, 
    0.042807692, 0.042807692, 0.042807692, 0.042807692, 0.042807692, 
    -0.282192308, -0.282192308, -0.282192308, -0.282192308, -0.282192308, 
    -0.282192308, -0.427192308, -0.427192308, -0.427192308, -0.427192308, 
    -0.427192308, -0.427192308, -0.027192308, -0.027192308, -0.027192308, 
    -0.027192308, -0.027192308, -0.027192308, 0.022807692, 0.022807692, 
    0.022807692, 0.022807692, 0.022807692, 0.022807692, 0.042807692, 
    0.042807692, 0.042807692, 0.042807692, 0.042807692, 0.042807692, 
    -0.267192308, -0.267192308, -0.267192308, -0.267192308, -0.267192308, 
    -0.267192308, -0.312192308, -0.312192308, -0.312192308, -0.312192308, 
    -0.312192308, -0.312192308, 0.062807692, 0.062807692, 0.062807692, 
    0.062807692, 0.062807692, 0.062807692, 0.127807692, 0.127807692, 
    0.127807692, 0.127807692, 0.127807692, 0.127807692, -0.592192308, 
    -0.592192308, -0.592192308, -0.592192308, -0.592192308, -0.592192308, 
    -0.612192308, -0.612192308, -0.612192308, -0.612192308, -0.612192308, 
    -0.612192308, -0.597192308, -0.597192308, -0.597192308, -0.597192308, 
    -0.597192308, -0.597192308, -0.607192308, -0.607192308, -0.607192308, 
    -0.607192308, -0.607192308, -0.607192308, -0.327192308, -0.327192308, 
    -0.327192308, -0.327192308, -0.327192308, -0.327192308, -0.572192308, 
    -0.572192308, -0.572192308, -0.572192308, -0.572192308, -0.572192308, 
    -0.622192308, -0.622192308, -0.622192308, -0.622192308, -0.622192308, 
    -0.622192308, -0.572192308, -0.572192308, -0.572192308, -0.572192308, 
    -0.572192308, -0.572192308, -0.577192308, -0.577192308, -0.577192308, 
    -0.577192308, -0.577192308, -0.577192308, -0.272192308, -0.272192308, 
    -0.272192308, -0.272192308, -0.272192308, -0.272192308, -0.547192308, 
    -0.547192308, -0.547192308, -0.547192308, -0.547192308, -0.547192308, 
    -0.607192308, -0.607192308, -0.607192308, -0.607192308, -0.607192308, 
    -0.607192308, 0.552807692, 0.552807692, 0.552807692, 0.552807692, 
    0.552807692, 0.552807692, 0.402807692, 0.402807692, 0.402807692, 
    0.402807692, 0.402807692, 0.402807692, 0.777807692, 0.777807692, 
    0.777807692, 0.777807692, 0.777807692, 0.777807692, 0.752807692, 
    0.752807692, 0.752807692, 0.752807692, 0.752807692, 0.752807692, 
    0.752807692, 0.752807692, 0.752807692, 0.752807692, 0.752807692, 
    0.752807692, 0.402807692, 0.402807692, 0.402807692, 0.402807692, 
    0.402807692, 0.402807692, 0.292807692, 0.292807692, 0.292807692, 
    0.292807692, 0.292807692, 0.292807692, 0.667807692, 0.667807692, 
    0.667807692, 0.667807692, 0.667807692, 0.667807692, 0.677807692, 
    0.677807692, 0.677807692, 0.677807692, 0.677807692, 0.677807692, 
    0.777807692, 0.777807692, 0.777807692, 0.777807692, 0.777807692, 
    0.777807692, 0.252807692, 0.252807692, 0.252807692, 0.252807692, 
    0.252807692, 0.252807692, 0.352807692, 0.352807692, 0.352807692, 
    0.352807692, 0.352807692, 0.352807692, 0.502807692, 0.502807692, 
    0.502807692, 0.502807692, 0.502807692, 0.502807692, 0.027807692, 
    0.027807692, 0.027807692, 0.027807692, 0.027807692, 0.027807692, 
    0.077807692, 0.077807692, 0.077807692, 0.077807692), c.temp = c(-4.095807692, 
    -4.095807692, -4.095807692, -4.095807692, -4.095807692, -4.095807692, 
    -4.220807692, -4.220807692, -4.220807692, -4.220807692, -4.220807692, 
    -4.220807692, -4.210807692, -4.210807692, -4.210807692, -4.210807692, 
    -4.210807692, -4.210807692, -4.175807692, -4.175807692, -4.175807692, 
    -4.175807692, -4.175807692, -4.175807692, -4.035807692, -4.035807692, 
    -4.035807692, -4.035807692, -4.035807692, -4.035807692, -3.920807692, 
    -3.920807692, -3.920807692, -3.920807692, -3.920807692, -3.920807692, 
    -3.820807692, -3.820807692, -3.820807692, -3.820807692, -3.820807692, 
    -3.820807692, -3.640807692, -3.640807692, -3.640807692, -3.640807692, 
    -3.640807692, -3.640807692, -3.660807692, -3.660807692, -3.660807692, 
    -3.660807692, -3.660807692, -3.660807692, -3.620807692, -3.620807692, 
    -3.620807692, -3.620807692, -3.620807692, -3.620807692, 0.074192308, 
    0.074192308, 0.074192308, 0.074192308, 0.074192308, 0.074192308, 
    -0.015807692, -0.015807692, -0.015807692, -0.015807692, -0.015807692, 
    -0.015807692, 0.324192308, 0.324192308, 0.324192308, 0.324192308, 
    0.324192308, 0.324192308, 0.544192308, 0.544192308, 0.544192308, 
    0.544192308, 0.544192308, 0.544192308, 0.759192308, 0.759192308, 
    0.759192308, 0.759192308, 0.759192308, 0.759192308, 1.324192308, 
    1.324192308, 1.324192308, 1.324192308, 1.324192308, 1.324192308, 
    1.549192308, 1.549192308, 1.549192308, 1.549192308, 1.549192308, 
    1.549192308, 1.709192308, 1.709192308, 1.709192308, 1.709192308, 
    1.709192308, 1.709192308, 1.639192308, 1.639192308, 1.639192308, 
    1.639192308, 1.639192308, 1.639192308, 1.579192308, 1.579192308, 
    1.579192308, 1.579192308, 1.579192308, 1.579192308, 2.724192308, 
    2.724192308, 2.724192308, 2.724192308, 2.724192308, 2.724192308, 
    2.839192308, 2.839192308, 2.839192308, 2.839192308, 2.839192308, 
    2.839192308, 1.064192308, 1.064192308, 1.064192308, 1.064192308, 
    1.064192308, 1.064192308, 1.184192308, 1.184192308, 1.184192308, 
    1.184192308, 1.184192308, 1.184192308, 1.254192308, 1.254192308, 
    1.254192308, 1.254192308, 1.254192308, 1.254192308, 1.379192308, 
    1.379192308, 1.379192308, 1.379192308, 1.379192308, 1.379192308, 
    1.529192308, 1.529192308, 1.529192308, 1.529192308, 1.529192308, 
    1.529192308, 1.599192308, 1.599192308, 1.599192308, 1.599192308, 
    1.599192308, 1.599192308, 1.669192308, 1.669192308, 1.669192308, 
    1.669192308, 1.669192308, 1.669192308, 1.664192308, 1.664192308, 
    1.664192308, 1.664192308, 1.664192308, 1.664192308, 1.714192308, 
    1.714192308, 1.714192308, 1.714192308, 1.714192308, 1.714192308, 
    0.984192308, 0.984192308, 0.984192308, 0.984192308, 0.984192308, 
    0.984192308, -1.545807692, -1.545807692, -1.545807692, -1.545807692, 
    -1.545807692, -1.545807692, -1.475807692, -1.475807692, -1.475807692, 
    -1.475807692, -1.475807692, -1.475807692, -1.460807692, -1.460807692, 
    -1.460807692, -1.460807692, -1.460807692, -1.460807692, -1.340807692, 
    -1.340807692, -1.340807692, -1.340807692, -1.340807692, -1.340807692, 
    -1.265807692, -1.265807692, -1.265807692, -1.265807692), 
    c.wind = c(1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, 1.27535159, 1.27535159, 1.27535159, 1.27535159, 
    1.27535159, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, -2.96855001, -2.96855001, -2.96855001, -2.96855001, 
    -2.96855001, 4.71144999, 4.71144999, 4.71144999, 4.71144999, 
    4.71144999, 4.71144999, 4.71144999, 4.71144999, 4.71144999, 
    4.71144999, 4.71144999, 4.71144999, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, -2.939182972, -2.939182972, 
    -2.939182972, -2.939182972, -2.939182972, 5.88092439, 5.88092439, 
    5.88092439, 5.88092439, 5.88092439, 5.88092439, 5.88092439, 
    5.88092439, 5.88092439, 5.88092439, 5.88092439, 5.88092439, 
    5.88092439, 5.88092439, 5.88092439, 5.88092439, 5.88092439, 
    5.88092439, 5.88092439, 5.88092439, 5.88092439, 5.88092439, 
    5.88092439, 5.88092439, 5.88092439, 5.88092439, 5.88092439, 
    5.88092439), c.distance = c(-160L, -160L, -160L, -160L, -160L, 
    -160L, -110L, -110L, -110L, -110L, -110L, -110L, -10L, -10L, 
    -10L, -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 90L, 190L, 
    190L, 190L, 190L, 190L, 190L, -160L, -160L, -160L, -160L, 
    -160L, -160L, -110L, -110L, -110L, -110L, -110L, -110L, -10L, 
    -10L, -10L, -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 90L, 
    190L, 190L, 190L, 190L, 190L, 190L, -160L, -160L, -160L, 
    -160L, -160L, -160L, -110L, -110L, -110L, -110L, -110L, -110L, 
    -10L, -10L, -10L, -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 
    90L, 190L, 190L, 190L, 190L, 190L, 190L, -160L, -160L, -160L, 
    -160L, -160L, -160L, -110L, -110L, -110L, -110L, -110L, -110L, 
    -10L, -10L, -10L, -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 
    90L, 190L, 190L, 190L, 190L, 190L, 190L, -160L, -160L, -160L, 
    -160L, -160L, -160L, -110L, -110L, -110L, -110L, -110L, -110L, 
    -110L, -110L, -110L, -110L, -110L, -110L, -10L, -10L, -10L, 
    -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 90L, 190L, 190L, 
    190L, 190L, 190L, 190L, -160L, -160L, -160L, -160L, -160L, 
    -160L, -110L, -110L, -110L, -110L, -110L, -110L, -10L, -10L, 
    -10L, -10L, -10L, -10L, 90L, 90L, 90L, 90L, 90L, 90L, 190L, 
    190L, 190L, 190L, 190L, 190L, -160L, -160L, -160L, -160L, 
    -160L, -160L, -10L, -10L, -10L, -10L, -10L, -10L, 90L, 90L, 
    90L, 90L, 90L, 90L, 190L, 190L, 190L, 190L, 190L, 190L, -160L, 
    -160L, -160L, -160L, -160L, -160L, -110L, -110L, -110L, -110L
    )), .Names = c(
      "SUR.ID",
      "tm",
      "ValidDetections",
      "CountDetections",
      "FalseDetections",
      "replicate",
      "Area",
      "Day",
      "R.det",
      "c.receiver.depth",
      "c.tm.depth",
      "c.temp",
      "c.wind",
      "c.distance"
    ), row.names = c(NA,-220L), class = "data.frame")

saveRDS(df, file = 'data/convergence.RDS')
```

```{r init-data}
# df = readRDS(
#   gzcon(
#     url('https://github.com/m-clark/m-clark.github.io/raw/master/data/convergence.RDS')
#   )
# )

df = readRDS('data/convergence.RDS')

df = df %>% 
  mutate(
    SUR.ID = factor(SUR.ID),
    replicate = factor(replicate),
    Unit = factor(1:n())
  )
```


```{r df-no-zeros, echo=FALSE}
df_no_zeros = df %>% 
  filter(CountDetections > 0)
```


## Initial model

The following is the model that led to the stackoverflow post.  It's fairly complicated with multiple interactions and random effects, modeling the proportion of valid detections via a binomial model.  The `Unit` effect is used to account for overdispersion, a common issue in count modeling.

```{r init-fit, warning=TRUE}
model_mixed_0 = glmer(
  cbind(ValidDetections, FalseDetections) ~ 
    tm:Area + tm:c.distance + c.distance:Area + c.tm.depth:Area + 
    c.receiver.depth:Area + c.temp:Area + c.wind:Area + c.tm.depth + 
    c.receiver.depth + c.temp + c.wind + tm + c.distance + Area + replicate + 
    (1|SUR.ID) + (1|Day) + (1|Unit), 
  data = df, 
  family = binomial()
)
```

This gives several warnings, the more egregious of which is that the model has not converged, meaning the estimates may not be trustworthy.  So what do we do?


## Step back 

The first step is to step back and look at the data. Are there issues that can be spotted? Are some essentially collinear with others?  In the following, we can see that some variables are only a few levels, and some, like `Day`, `c.tm.depth` and `c.receiver.depth`, are both notably correlated with each other and with other predictor variables. 

```{r init-data-show, echo=FALSE}
tidyext::describe_all(df %>% select(-Unit))
```

```{r correlation, echo=FALSE}
df %>% 
  select(-Unit, -SUR.ID, -CountDetections) %>% 
  mutate_all(as.numeric) %>% 
  cor(use = 'pair') %>% 
  visibly::corr_heat()
```


We can obtain a rough metric of total correlation of a variable with the others by looking at the [variance inflation factor](https://en.wikipedia.org/wiki/Variance_inflation_factor) (VIF)[^vif].  For this, we'll treat any binary or ordered data as numeric, and we can use the <span class="pack" style = "">car</span> package to get the VIF.  This requires running an arbitrary regression model that includes the covariates of interest, but the value is derived only from the predictor variables. If we just try it with a dummy model, we get an error, since the linear  model has perfect collinearity.  We  find out that `Day` is probably causing issues, and we'll see why later.

```{r inspect-vif}
# the model used to acquire the vif doesn't matter- anything could be used for
# the target variable

# this produces errors about aliased coefficients
# car::vif(lm(CountDetections ~ . - Unit - FalseDetections - ValidDetections, dat = df))

attributes(alias(
  lm(
    CountDetections ~ . - Unit - FalseDetections - ValidDetections,
    dat = df
  )
)$Complete)$dimnames[[1]]

car::vif(lm(CountDetections ~ . -Unit -Day -FalseDetections, dat = df))
```

It looks like, along with `Day`, `tm.depth` is probably going to cause a problem, as more than 90% of its variance is accounted for by the other covariates.   So at this point we can consider both it and `Day` as potential predictors to remove.  Wind is less an issue once `Day` is removed.

An alternative approach I tried (not shown) was just running a PCA on the predictor variables.  Only six components were needed to account for nearly almost 90% of the total variance, so I think it's safe to say there is a notable amount of redundancy in this data.

One final note is that the target variable is a potential problem as well. More than half of the data is a 1.0 proportion of `Valid Detections`, and it also turns out this doesn't appear to be proportional data per se, as sometimes both Valid and False Detections can be zero, meaning such observations don't contribute meaningfully to the model.  This isn't necessarily a problem as these observations are basically dropped dropped from the model, and you will note in the GLM results that follow that the residual degrees of freedom will be notably lower than the total number of observations (`r nrow(df)`). This is due to the dropout of those observations, which is about `r rnd((1 - nrow(df_no_zeros)/nrow(df))*100, 0)`% of the data. Even so, the lack of variability may be an underlying issue in general.  Especially in the case of interactions, it is likely that some cells have no variability in the outcome.

## Start simply

So we know there are some data issues, so let's start with a model that's relatively simple but still plausible. If we just look at a GLM without any random effects, can we spot any issues?  


```{r model_glm-glm}
model_glm_1 = glm(
  cbind(ValidDetections, FalseDetections) ~
    tm:Area + tm:c.distance + c.distance:Area + c.tm.depth:Area +
    c.receiver.depth:Area + c.temp:Area + c.wind:Area + c.tm.depth +
    c.receiver.depth + c.temp + c.wind + tm + c.distance + Area + replicate +
    SUR.ID + Day,
  data = df,
  family = binomial(link = 'logit')
)

summary(model_glm_1)
```

Sure enough, there are problems. What's going on with `Day` and `Area`? One issue is that `Area` only couples with certain days, so having one already tells you a lot about what the other could tell you.  

```{r day-area-table}
with(df, table(Day, Area))
```

You could potentially create a combined type of variable to deal with this for example, but otherwise the problem will persist with both in the model. There are likely remaining collinearities besides, but let's take Day out for example.

```{r glm-no-day}
model_glm_2 = update(model_glm_1, . ~ . -Day)

summary(model_glm_2)
```

Well, at least we got rid of the complete collinearity- no `NA` remains. However, those familiar with such models can still see that some of these coefficients and their associated standard errors are exceedingly large for this setting, so we shouldn't really be surprised there would still be issues with the more complicated mixed models.  With binary logistic models, large absolute coefficients and their standard errors are usually a sign of collinearity/separation, and we now know from our previous exploration that something similar is going on in this proportional binomial model.  Here is a table of the more egregious offenders and a plot of all coefficients, their standard errors, and the VIF (size).

```{r glm-issues, echo=FALSE, dev.args=list(bg="transparent")}
init = tidy(model_glm_2) %>% 
  slice(-1, -11) %>% 
  bind_cols(tibble(vif = car::vif(model_glm_2)[,3])) # use the adjusted one

init %>% 
  top_n(5, abs(estimate)) %>% 
  kable_df()

init %>%
  ggplot(aes(abs(estimate), std.error)) +
  geom_point(aes(size = vif), color = '#ff5500', alpha = .5) +
  scale_size_continuous(trans = 'log') +
  theme_clean()
```

At this point I would not assume anything about the mixed model itself being a problem, and be leaning toward this being primarily a data issue.  Or, at the very least, data issues will need to be sorted out.  So let's begin the restart of our mixed model effort by pulling out some of those variables we thought had some collinearity issues.  You might have noticed from the GLM that `SUR.ID` was only 3 levels, so let's move that to a fixed effect also.  In keeping things simple, I'm not including any interactions.

```{r model_mixed_1, warning=TRUE, message=TRUE}
model_mixed_1 = glmer(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance + c.distance:Area + #c.tm.depth:Area + 
    # c.receiver.depth:Area + c.temp:Area + c.wind:Area + #c.tm.depth + 
    c.receiver.depth + c.temp + c.wind + tm + c.distance + Area + replicate + 
    SUR.ID + 
    (1|Unit), #  + (1|Day)
  data = df,
  family = binomial(link = 'logit')
)


summarize_model(model_mixed_1, ci = FALSE)
```

Well, we still have issues, so what else can we try?

## Rescale variables

Let's go ahead with the easy part and rescale our variables, which might as well be done with any model.  I will standardize the numeric variables.

```{r model_mixed_2-rescale, warning=TRUE, message=TRUE}
sc = function(x) scale(x)[, 1]

df = df %>% 
  mutate(
    c.receiver.depth_sc = sc(c.receiver.depth),
    c.tm.depth_sc = sc(c.tm.depth),
    c.temp_sc     = sc(c.temp),
    c.wind_sc     = sc(c.wind),
    c.distance_sc = sc(c.distance),
  )

model_mixed_2 = glmer(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area + 
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc + c.temp_sc + c.wind_sc + tm + c.distance_sc + Area + replicate + 
    SUR.ID +
    (1|Unit), 
  data = df,
  family = binomial(link = 'logit')
)

summarize_model(model_mixed_2, ci = FALSE)
```

So at least we have the rescaling taken care of, and while that got rid of one warning, we still have the convergence problem.  What can we check for next?  I looked to see if there was any further imbalance of  categorical variables, didn't spot much issue, but then discovered something else.  A couple covariates - `c.wind` and `c.distance` - have only five unique values, and for the former, some of those values only occur a few times.  In addition, `c.wind` was unique per day, so was essentially confounded with it.  So we can feel fine with having previously removed Day.

```{r inspect-wind}
df %>% 
  select(-ends_with('sc')) %>% 
  map_int(n_distinct)

table(df$c.wind, df$Day)
```

<br>

If we treat these as categorical what happens?  I'll do it just for the GLM again.

```{r model_glm_3}
model_glm_3 = glm(
  cbind(ValidDetections, FalseDetections) ~
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area +
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc + c.temp_sc + factor(c.wind) + tm + factor(c.distance) + Area + replicate +
    SUR.ID ,
  data = df,
  family = binomial(link = 'logit')
)

summary(model_glm_3)
```

Ah! So now we see that `Area` is also accounted for by other factors.  In addition, wind is still problematic.  Let's take out `Area`, while still treating wind and distance as categorical for our diagnostic adventure.

```{r table-wind-area, echo=FALSE, eval=FALSE}
table(df$c.wind, df$Area)
```

```{r model_glm_4}
model_glm_4 =  update(model_glm_3, . ~ . - Area)

summary(model_glm_4)
```

The remaining collinearity is due to the relatively few observations for that value of wind, but at least most of the other covariates effects have settled down.  Let's try collapsing wind values and officially making it categorical.

```{r model_mixed_3}
df = df %>% 
  mutate(wind = fct_lump(factor(c.wind), 3, other_level = 'Higher'))

table(df$wind)

model_mixed_3 = glmer(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area + 
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc + c.temp_sc + wind + tm + factor(c.distance) + #Area + 
    replicate + SUR.ID +
    (1|Unit), 
  data = df, 
  family = binomial(link = 'logit')
)

summarize_model(model_mixed_3, ci = FALSE)
```

Checking VIF adjusted for the degrees of freedom associated with the covariate (which is greater for categorical variables), we still have some issues.  Below I show VIF both with and without wind as an example.


```{r wind-vif, echo = F}
vif_wind = car::vif(glm(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area + 
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc + c.temp_sc + wind + tm + factor(c.distance) + #Area + 
    replicate + SUR.ID, 
  data = df, 
  family = binomial(link=logit)
)) %>% 
  as_tibble(rownames = 'covariate') %>% 
  rename(VIF_adj_orig = `GVIF^(1/(2*Df))`)

vif_no_wind = car::vif(glm(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area + 
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc + c.temp_sc + tm + factor(c.distance) + #Area + 
    replicate + SUR.ID, 
  data = df, 
  family = binomial(link=logit)
)) %>% 
  as_tibble(rownames = 'covariate') %>% 
  rename(VIF_adj = `GVIF^(1/(2*Df))`)

left_join(vif_wind, vif_no_wind, "covariate") %>% 
  select(covariate, VIF_adj_orig, VIF_adj) %>% 
  kable_df()
```

Let's see what happens if we remove wind from the model.

```{r model_mixed_4, warning=TRUE}
model_mixed_4 = glmer(
  cbind(ValidDetections, FalseDetections) ~ 
    # tm:Area + tm:c.distance_sc + c.distance_sc:Area + 
    # c.receiver.depth_sc:Area + c.temp_sc:Area + c.wind_sc:Area +
    c.receiver.depth_sc +  c.temp_sc  + tm + factor(c.distance) + #Area + 
    replicate + SUR.ID +
    (1|Unit), 
  data = df,
  family = binomial(link = 'logit')
)

summarize_model(model_mixed_4, ci = FALSE)
```

We're doing better, as our `max|grad|` value is closer to the tolerance value, but we're still not where we want to be.  What else can we do?


## Remove zero random effects

If any variance components estimates are zero we could remove them.  However, at this point we already have. `Day` was zero because it was already accounted for by other covariates. `SUR.ID`  moved to a fixed effect, where it still appears to be a small effect, but at least won't cause computational problems. The remaining `Unit` effect does appear to capture some overdispersion, so we can leave it for now.

## Technical options

At this point, we have explored some of the more problematic aspects of the data.  Some might feel that they are missing out on some of their theoretical priorities by removing some covariates, but if they are confounded with other covariates, their story can't be easily disentangled anyway. As noted, we could still play around with creation of different categorical effects through further collapsing or combining, but a lot of that would be arbitrary, so must be done with caution.  

In general, the problems with the model appear to actually be entirely with the data, but we can move on for demonstration.  At some point in your own modeling adventure, you may exhaust what you can do data-wise, and still have convergence issues.  This leaves exploration of the more technical side of things to see what tweaks can be made to help further. In order to best check these more technical aspects, it helps to know something about the underlying optimization algorithms, or at least optimization in general. And in general, I suggest refraining from this unless the previous steps have failed.  It is very common that once the data has been sorted, convergence gets solved as well, so the data must be ruled out.  In any case, let's see what else we can do!

### Check singularity

This is a mixed model-specific check[^convergence], and in general, checking singularity[^singularity] goes along with removing zero random effects. These days, you'll usually get a singularity warning when it is likely the case. In the past, Bolker suggested checking this problem as follows, but for this example concluded the result wasn't close enough to zero to be a real concern.  The `theta` below are just our random effect standard deviations, and I would say that the ones besides `Unit` probably weren't meaningfully different from zero.

```{r check-singularity}
thetas = getME(model_mixed_0, "theta")

thetas

ll = getME(model_mixed_0, "lower") # lower bounds on model parameters (random effects parameters only)

min(thetas[ll == 0])
```

Nowadays <span class="pack" style = "">lme4</span> provides the function <span class="func" style = "">isSingular</span> which uses the steps above to check the minimum value against some specified tolerance. 

```{r check-singularity2}
isSingular(model_mixed_0, tol = 1e-5)
# rePCA(model_mixed_0)  # via PCA of the random-effects variance-covariance estimates
```


### Double-checking gradient calculations

For the mixed model setting, Bolker notes the following:

> One general problem is that large scaled gradients are often associated with small absolute gradients: we might decide that we're more interested in testing the (parallel) minimum of these two quantities.

We can do this as follows for the initial mixed model. 

```{r check-gradients}
derivs_init  = model_mixed_0@optinfo$derivs

sc_grad_init = with(derivs_init, solve(Hessian, gradient))

max(abs(sc_grad_init))

max(pmin(abs(sc_grad_init), abs(derivs_init$gradient)))
```

We see that the unscaled gradient results in a lower maximum value, but is still large relative to the tolerance. That value is what is reported in the warning message. 

```{r init-warning-message}
model_mixed_0@optinfo$conv$lme4$messages[[1]]
```


It may be instructive to compare the result to the model where we scaled the inputs. In this case the scaled gradient results in the lower max value.

```{r check_gradients2}
derivs_model_mixed_2 = model_mixed_2@optinfo$derivs

sc_grad_model_mixed_2 = with(derivs_model_mixed_2, solve(Hessian, gradient))

max(abs(sc_grad_model_mixed_2))

max(pmin(abs(sc_grad_model_mixed_2), abs(derivs_model_mixed_2$gradient)))
```

Bolker also suggests checking if the result varies from using a different calculation, but it's not clear what we'd do if this was the case.  In any event, the results would be similar.

```{r check-gradients-num-deriv}
devfun_init  = update(model_mixed_0, devFunOnly = TRUE)
pars_init    = unlist(getME(model_mixed_0, c("theta", "fixef")))
grad_init    = numDeriv::grad(devfun_init, pars_init)
hess_init    = numDeriv::hessian(devfun_init, pars_init)
sc_grad_init = solve(hess_init, grad_init)

max(pmin(abs(sc_grad_init), abs(grad_init)))

max(pmin(abs(sc_grad_init), abs(derivs_init$gradient)))
```


### Restart the fit

As another step along our technical travails, we can just let the optimizer keep going until it does converge.   Many R modeling packages allow for you to access the optimizer and change various settings.  Most optimizers have a `maxit` type of argument to let you set the number of iterations, and we can use <span class="func" style = "">update</span> to continue where we left off.  Unfortunately there is no standard argument name for the total number of iterations, or even if you do happen to remember, guessing is required as to what we should set it at.  So instead, we can just call <span class="func" style = "">update</span> iteratively until there is no convergence warning.  I check this by seeing if there is any output to `@optinfo$conv$lme4`, as it will only be there if it doesn't converge[^optinfo].

```{r restart}
model_mixed_5 = model_mixed_4

while (length(model_mixed_5@optinfo$conv$lme4) > 0) {
  pars = getME(model_mixed_5,c("theta","fixef"))
  model_mixed_5 <-
    update(model_mixed_5,
           start = pars,
           control = glmerControl(optCtrl = list(maxfun = 2e5)))
}

max(
  abs(
    with(
      model_mixed_5@optinfo$derivs, solve(Hessian, gradient)
    )
  )
)  
# we win!
```

So at this point we have converged with no warnings.  Hooray for us!  However, the following shows us that we were pretty close anyway.  The estimates from the last model with warnings and the converged model are nearly identical.

```{r compare-converged, message = TRUE}
summarize_model(model_mixed_4, ci = 0)
summarize_model(model_mixed_5, ci = 0)
```

As an additional point, one may provide starting estimates from the outset.  For example you could run a a simpler model, e.g. standard GLM, and feed the estimates there for the fixed effects coefficients of the mixed model, or even run a model to obtain starting values for the random effects (see this [example](https://gist.githubusercontent.com/bbolker/ea8ed558d9fe0a4a1a6909039242eb87/raw/a493a6c5dc8231577b22de9fc29808ac02da29c7/lme4_GH858.R)).


### Change the optimizer

As a last effort among the more technical knobs to turn, we can start fiddling with the optimizer options. The <span class="pack" style = "">lme4</span> package has a nice function <span class="func" style = "">allFit</span> that will search across several different optimizers (some may require additional packages to be installed). However, in any particular modeling setting you could potentially do this, though often you may not be able to without quite a bit of effort relative to what <span class="pack" style = "">lme4</span> allows.  I'll do this with our last non-converged model.


```{r allfit}
library(optimx)  # required for some optimizers

glmm_all = allFit(model_mixed_4)

glmm_all_summary = summary(glmm_all)
```

The '[OK]' just means there wasn't an error, however we can see that several have convergence problems, but even a couple of those are almost to the tolerance level.  In the end though, the estimates and log likelihoods are not meaningfully different across the optimizers.

```{r allfit-result, echo=FALSE}
tibble(
  opt = rownames(glmm_all_summary$fixef),
  OK = glmm_all_summary$which.OK,
  Message = glmm_all_summary$msgs
) %>%
  unnest(cols = Message) %>%
  kable_df()


bind_cols(as_tibble(glmm_all_summary$fixef),
          tibble(ll = glmm_all_summary$llik)) %>%
  mutate(optimizer = names(glmm_all)) %>%
  select(optimizer, everything()) %>%
  kable_df() %>%
  scroll_box(width = '768px')
```


The conclusion would be that our estimates are probably okay regardless of chosen optimizer, but the data likely has issues that still need to be overcome.  

Along with different optimizers comes trying different packages. Some packages, in this case like <span class="pack" style = "">glmmTMB</span> or <span class="pack" style = "">brms</span>, would be viable options.  In my playing around with those, <span class="pack" style = "">glmmTMB</span> converged, but obviously doesn't magically overcome the collinearity problems.  Likewise, <span class="pack" style = "">brms</span> appeared to converge, but had other estimation issues specific to it.  Unlike the others, <span class="pack" style = "">brms</span> also noted that the zero count observations could not be used.

## Final Step

The final step would be to make some hard decisions about the model.  Which predictors are most meaningful? Is this the best target variable available? Is this the right way to think about the distribution of the target? Is the research question clear enough? Is it strongly related to the available data, enough to be answerable?[^barth]

However, these are more theoretical problems, not so much statistical ones, and there may be no right answer in the end. That is perfectly fine, and just what you'd report to others. The following model has no issues, but may leave more questions than answers. 

```{r final-model, message=TRUE}
model_mixed_final = glmer(
  ValidDetections ~ 
    c.receiver.depth_sc + c.temp_sc + tm + 
    replicate + SUR.ID + (1|Unit),
    data = df,
    family = poisson
    )

summarize_model(model_mixed_final, ci = 0)
```




## Summary

We can summarize our approach to convergence problems as follows:

0. Step back and look at your data. Are there issues? Are some variables essentially collinear with others or otherwise can be practically reduced?

1. Start with the simplest but still plausible model. Do you spot any additional issues?  If there are, these probably need to be remedied before moving to more complex models.

2. Scale your continuous variables. You should be doing this anyway. If some categorical levels have very relatively few observations, consider collapsing.

3. For mixed models, if some of your random effects only have a few levels, treat them as fixed or see if they are even needed in the model.

4. For mixed models, are any random effect variance estimates zero or nearly zero? Remove.

5. After some initial technical checks, if possible, restart the model using previous starting values, and run until convergence. Many packages provide some functionality in this regard, but what exactly is provided may be limited.

6. Change the optimizer (if a small mixed model using <span class="pack" style = "">lme4</span>, compare several with <span class="func" style = "">allFit</span> function). 
    - If log-likelihood and parameter estimates are pretty much the same across optimizers (and they are rarely notably different in my experience), pick one and go with it.
    
6. Use a different package.  The different estimation approach may simply work better for the current problem or provide other opportunities for tweaks.  For example, with mixed models one could use <span class="pack" style = "">glmmTMB</span> or <span class="pack" style = "">brms</span> (Bayesian) in lieu of <span class="pack" style = "">lme4</span>.


In my experience with many clients with many types of data coming across many fields of study, the usual problem with convergence and <span class="pack" style = "">lme4</span> (and others) is typically a fixable data problem, or a problematically specified model.  In this case, the <span class="pack" style = "">lme4</span> developers have worked hard over a number of years to build this awesome tool, and it works very well, so if it is having problems, you should be inspecting your data closely and thinking hard about your model.  If it is an <span class="pack" style = "">lme4</span> problem, switching optimizers will likely get you to convergence, but going through technical solutions should be a last resort.

## References

Bates et al.[@bates2015parsimonious]

<br>

Stackoverflow question[@stackoverflow2014]

<br>

Bolker's answer given a little more cleanly[@bolker2014]

<br>

Help file for convergence[@lme4convergence2020]

[^bolker]: Ben Bolker is one of the primary developers of the <span class="pack" style = "">lme4</span> package.

[^vif]: For a basic linear model situation, $1-1/VIF = R^2$, where $R^2$ is a regression model where a covariate is predicted by all the other covariates.  We wouldn't typically use a standard linear regression for binary outcomes or other scenarios, but this provides a quick and rough metric. The car package actually also provides a 'generalized' VIF though. In terms of interpretation, it tells us how much the standard error increases relative to the covariate if it was independent of the others.  We would be concerned with redundancy of anything of VIF > 10 /  $R^2$ > .90, but maybe even less.  As a final note, collinearity is basically a sample size issue, as larger data would reduce the standard errors, and we'd likely get a fuller sense of true variability in the covariates.


[^convergence]: This outline mostly follows the documentation in the help file for `?convergence` for lme4.

[^singularity]: Think of doing a principal components analysis on the variance-covariance matrix for the random effects. If one of those components is essentially accounting for zero variance, it may suggest at least one of the estimated random effects is not needed.

[^optinfo]: Unfortunately there doesn't appear to be much documentation on what should be listed in `optinfo`.

[^barth]: To paraphrase Barthelme slightly: "What is wonderful? Are these results wonderful? Are they significant? Are they what I need?"